{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samema\\OneDrive\\LV_Data\\.venv\\Lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 13.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data manipulation and processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from numpy import nanmean\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "from colorama import Fore, Style, init\n",
    "\n",
    "# Modeling\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import torch\n",
    "import shap\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('c:\\\\Users\\\\samema\\\\DB\\\\LV_Data2\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('df_full_2024_09_27.csv', )\n",
    "df_test = pd.read_csv('df_full_test_2024_09_27.csv', )\n",
    "df_30 = pd.read_csv('df_30_day_2024_09_27.csv', )\n",
    "df_60 = pd.read_csv('df_60_day_2024_09_27.csv', )\n",
    "df_90 = pd.read_csv('df_90_day_2024_09_27.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled successfully.\n",
      "Features scaled successfully.\n",
      "Features scaled successfully.\n",
      "Features scaled successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "class FeatureScaler:\n",
    "    def __init__(self, train, target, test=None, exclude_columns=None):\n",
    "        \"\"\"\n",
    "        Initializes the FeatureScaler with training data, target column, and optionally test data.\n",
    "        \n",
    "        Parameters:\n",
    "            train (pd.DataFrame): Training data.\n",
    "            target (str): The name of the target column.\n",
    "            test (pd.DataFrame, optional): Test data. Default is None.\n",
    "            exclude_columns (list of str, optional): Columns to exclude from scaling. Default is None.\n",
    "        \"\"\"\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.target = target\n",
    "        self.exclude_columns = exclude_columns if exclude_columns is not None else []\n",
    "        self.scaler = RobustScaler()\n",
    "\n",
    "    def scale_features(self):\n",
    "        \"\"\"\n",
    "        Scales the features using RobustScaler, excluding the target variable and any specified columns.\n",
    "        If a test DataFrame is provided, it scales the test data using the same parameters.\n",
    "        \"\"\"\n",
    "        features = [col for col in self.train.columns if col != self.target and col not in self.exclude_columns]\n",
    "        try:\n",
    "            with warnings.catch_warnings(record=True) as w:\n",
    "                warnings.simplefilter(\"always\", DataConversionWarning)\n",
    "                \n",
    "                self.train[features] = self.scaler.fit_transform(self.train[features])\n",
    "                \n",
    "                if self.test is not None:\n",
    "                    self.test[features] = self.scaler.transform(self.test[features])\n",
    "                \n",
    "                # Check for DataConversionWarnings\n",
    "                if any(issubclass(warning.category, DataConversionWarning) for warning in w):\n",
    "                    print(\"Data conversion issue encountered during scaling.\")\n",
    "                \n",
    "                print(\"Features scaled successfully.\")\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred during scaling:\", e)\n",
    "\n",
    "# Example usage\n",
    "# Assuming df_full, df_test, df_30, df_60, and df_90 are your DataFrames and 'encoded_category' is your target column name\n",
    "\n",
    "# Scale features for full data with test set, excluding the 'date' column\n",
    "feature_scaler_with_test = FeatureScaler(df_full, 'category', df_test, exclude_columns=['date'])\n",
    "feature_scaler_with_test.scale_features()\n",
    "\n",
    "# Scale features for 30-day data, excluding the 'date' column\n",
    "feature_scaler30 = FeatureScaler(df_30, 'category', exclude_columns=['date','Unnamed: 0'])\n",
    "feature_scaler30.scale_features()\n",
    "\n",
    "# Scale features for 60-day data, excluding the 'date' column\n",
    "feature_scaler60 = FeatureScaler(df_60, 'category', exclude_columns=['date','Unnamed: 0'])\n",
    "feature_scaler60.scale_features()\n",
    "\n",
    "# Scale features for 90-day data, excluding the 'date' column\n",
    "feature_scaler90 = FeatureScaler(df_90, 'category', exclude_columns=['date','Unnamed: 0'])\n",
    "feature_scaler90.scale_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine minimal_risk and low_risk into low_risk\n",
    "def combine_risk_categories(df):\n",
    "    df['category'] = df['category'].replace('minimal_risk', 'low_risk')\n",
    "    return df\n",
    "\n",
    "# Apply the function to each DataFrame\n",
    "df_full = combine_risk_categories(df_full)\n",
    "df_30 = combine_risk_categories(df_30)\n",
    "df_60 = combine_risk_categories(df_60)\n",
    "df_90 = combine_risk_categories(df_90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Step 1: Ordinal Encoding\n",
    "risk_categories = ['low_risk', 'low_medium_risk', 'medium_risk', 'medium_high_risk', 'high_risk']\n",
    "encoder = OrdinalEncoder(categories=[risk_categories])\n",
    "\n",
    "def encode_category(df):\n",
    "    df['encoded_category'] = encoder.fit_transform(df[['category']])\n",
    "    return df\n",
    "\n",
    "df_full = encode_category(df_full)\n",
    "df_test = encode_category(df_test)\n",
    "df_30 = encode_category(df_30)\n",
    "df_60 = encode_category(df_60)\n",
    "df_90 = encode_category(df_90)\n",
    "\n",
    "# Organize datasets into a dictionary\n",
    "datasets = {\n",
    "    'full_data': {'train': df_full, 'test': df_test},\n",
    "    '30_day_data': {'train': df_30, 'test': df_test},\n",
    "    '60_day_data': {'train': df_60, 'test': df_test},\n",
    "    '90_day_data': {'train': df_90, 'test': df_test}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "full_data - Train Merged Categories:\n",
      "merged_category\n",
      "1    7210\n",
      "0    6716\n",
      "Name: count, dtype: int64\n",
      "full_data - Test Merged Categories:\n",
      "merged_category\n",
      "1    1030\n",
      "0     478\n",
      "Name: count, dtype: int64\n",
      "\n",
      "30_day_data - Train Merged Categories:\n",
      "merged_category\n",
      "1    7210\n",
      "0    6716\n",
      "Name: count, dtype: int64\n",
      "30_day_data - Test Merged Categories:\n",
      "merged_category\n",
      "1    1030\n",
      "0     478\n",
      "Name: count, dtype: int64\n",
      "\n",
      "60_day_data - Train Merged Categories:\n",
      "merged_category\n",
      "1    7210\n",
      "0    6716\n",
      "Name: count, dtype: int64\n",
      "60_day_data - Test Merged Categories:\n",
      "merged_category\n",
      "1    1030\n",
      "0     478\n",
      "Name: count, dtype: int64\n",
      "\n",
      "90_day_data - Train Merged Categories:\n",
      "merged_category\n",
      "1    7210\n",
      "0    6716\n",
      "Name: count, dtype: int64\n",
      "90_day_data - Test Merged Categories:\n",
      "merged_category\n",
      "1    1030\n",
      "0     478\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the manual category mapping\n",
    "category_mapping = {\n",
    "    0.0: 0,\n",
    "    4.0: 1,\n",
    "    2.0: 1,\n",
    "    1.0: 1,\n",
    "    3.0: 1\n",
    "}\n",
    "\n",
    "# Function to apply category mapping\n",
    "def apply_manual_category_mapping(df, category_mapping):\n",
    "    df['merged_category'] = df['encoded_category'].map(category_mapping)\n",
    "    return df\n",
    "\n",
    "# Apply category mappings to all datasets\n",
    "datasets = {\n",
    "    'full_data': {'train': apply_manual_category_mapping(df_full, category_mapping), 'test': apply_manual_category_mapping(df_test, category_mapping)},\n",
    "    '30_day_data': {'train': apply_manual_category_mapping(df_30, category_mapping), 'test': apply_manual_category_mapping(df_test, category_mapping)},\n",
    "    '60_day_data': {'train': apply_manual_category_mapping(df_60, category_mapping), 'test': apply_manual_category_mapping(df_test, category_mapping)},\n",
    "    '90_day_data': {'train': apply_manual_category_mapping(df_90, category_mapping), 'test': apply_manual_category_mapping(df_test, category_mapping)}\n",
    "}\n",
    "\n",
    "# Verify the merged categories\n",
    "for key, dataset in datasets.items():\n",
    "    print(f\"\\n{key} - Train Merged Categories:\")\n",
    "    print(dataset['train']['merged_category'].value_counts())\n",
    "    print(f\"{key} - Test Merged Categories:\")\n",
    "    print(dataset['test']['merged_category'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns function\n",
    "def drop_columns(datasets):\n",
    "    for key, dataset in datasets.items():\n",
    "        # Dropping columns and ensuring the dataset is updated\n",
    "        dataset['train'] = dataset['train'].drop(columns=['category', 'date', 'Unnamed: 0','encoded_category'], errors='ignore')\n",
    "        dataset['test'] = dataset['test'].drop(columns=['category', 'date', 'Unnamed: 0', 'encoded_category'], errors='ignore')\n",
    "    return datasets\n",
    "\n",
    "\n",
    "\n",
    "datasets = drop_columns(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent to channel #hyperparametertuning: Hello from your bot! :tada:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "\n",
    "# Set the environment variable SLACK_BOT_TOKEN to your actual Slack bot token\n",
    "\n",
    "# Initialize the Slack client\n",
    "client = WebClient(token=os.environ['SLACK_BOT_TOKEN'])\n",
    "\n",
    "# Function to send a message\n",
    "def send_slack_message(channel_id, message):\n",
    "    try:\n",
    "        response = client.chat_postMessage(\n",
    "            channel=channel_id,\n",
    "            text=message\n",
    "        )\n",
    "        print(f\"Message sent to channel {channel_id}: {response['message']['text']}\")\n",
    "    except SlackApiError as e:\n",
    "        print(f\"Error posting message: {e.response['error']}\")\n",
    "\n",
    "# Replace 'your-channel-id' with the actual channel ID\n",
    "channel_id = '#hyperparametertuning'\n",
    "message = 'Hello from your bot! :tada:'\n",
    "\n",
    "# Send the message\n",
    "send_slack_message(channel_id, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score, accuracy_score, precision_score, recall_score,\n",
    "    fbeta_score, confusion_matrix\n",
    ")\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "import shap\n",
    "from typing import Dict, List\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def send_slack_message(channel_id: str, message: str):\n",
    "    client = WebClient(token=os.environ['SLACK_BOT_TOKEN'])\n",
    "    try:\n",
    "        response = client.chat_postMessage(channel=channel_id, text=message)\n",
    "        logging.info(f\"Message sent to channel {channel_id}: {response['message']['text']}\")\n",
    "    except SlackApiError as e:\n",
    "        logging.error(f\"Error posting message: {e.response['error']}\")\n",
    "\n",
    "class XGBoostPredictor:\n",
    "    def __init__(self, datasets: Dict[str, Dict[str, pd.DataFrame]], model_configs: dict, \n",
    "                 config_file: str = 'best_config.json', model_dir: str = 'models', slack_channel: str = None):\n",
    "        self.datasets = datasets\n",
    "        self.model_configs = model_configs\n",
    "        self.config_file = config_file\n",
    "        self.model_dir = model_dir\n",
    "        self.slack_channel = slack_channel\n",
    "        self.model_results = {}\n",
    "        self.ensemble_results = {}\n",
    "        self.best_params = {}\n",
    "        self.accumulated_X = pd.DataFrame()\n",
    "        self.accumulated_y = pd.Series(dtype=float)\n",
    "        self.shap_values_dict = {}\n",
    "\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        if os.path.exists(config_file):\n",
    "            os.remove(config_file)\n",
    "\n",
    "    def compute_metrics(self, y_true: pd.Series, y_pred: pd.Series, threshold: float) -> Dict[str, float]:\n",
    "        y_true_binary = (y_true >= threshold).astype(int)\n",
    "        y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "        return {\n",
    "            'Accuracy': accuracy_score(y_true_binary, y_pred_binary),\n",
    "            'Precision': precision_score(y_true_binary, y_pred_binary, average='binary', zero_division=0),\n",
    "            'Recall': recall_score(y_true_binary, y_pred_binary, average='binary', zero_division=0),\n",
    "            'F0.5 Score': fbeta_score(y_true_binary, y_pred_binary, beta=0.5, average='binary', zero_division=0)\n",
    "        }\n",
    "\n",
    "    def objective_f0_5(self, trial: optuna.Trial) -> float:\n",
    "        logging.info(f\"Starting trial {trial.number} for F0.5 optimization\")\n",
    "\n",
    "        xgb_params = {\n",
    "            'learning_rate': trial.suggest_float('xgb_learning_rate', 1e-4, 1e-1, log=True),\n",
    "            'n_estimators': trial.suggest_int('xgb_n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('xgb_max_depth', 3, 12),\n",
    "            'subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('xgb_reg_alpha', 1e-8, 1.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('xgb_reg_lambda', 1e-8, 1.0, log=True),\n",
    "            'tree_method': 'hist',\n",
    "            'device': 'cuda',\n",
    "            'early_stopping_rounds': 50\n",
    "        }\n",
    "\n",
    "        threshold = trial.suggest_float('threshold', 0.1, 0.9)\n",
    "\n",
    "        outer_kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        outer_fold_metrics = []\n",
    "\n",
    "        for train_index, test_index in outer_kf.split(self.accumulated_X):\n",
    "            X_train, X_test = self.accumulated_X.iloc[train_index], self.accumulated_X.iloc[test_index]\n",
    "            y_train, y_test = self.accumulated_y.iloc[train_index], self.accumulated_y.iloc[test_index]\n",
    "\n",
    "            inner_kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "            inner_fold_metrics = []\n",
    "\n",
    "            for inner_train_index, val_index in inner_kf.split(X_train):\n",
    "                X_inner_train, X_val = X_train.iloc[inner_train_index], X_train.iloc[val_index]\n",
    "                y_inner_train, y_val = y_train.iloc[inner_train_index], y_train.iloc[val_index]\n",
    "\n",
    "                model = XGBClassifier(**xgb_params)\n",
    "                model.fit(X_inner_train, y_inner_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "                y_val_pred = model.predict_proba(X_val)[:, 1]  # Predict probabilities for the positive class\n",
    "                metrics = self.compute_metrics(y_val, y_val_pred, threshold)\n",
    "                inner_fold_metrics.append(metrics)\n",
    "\n",
    "            avg_fbeta = np.nanmean([fm['F0.5 Score'] for fm in inner_fold_metrics if fm['F0.5 Score'] is not None])\n",
    "            outer_fold_metrics.append(avg_fbeta)\n",
    "\n",
    "        trial_fbeta = np.mean(outer_fold_metrics)\n",
    "        logging.info(f\"Trial {trial.number} completed with average F0.5 Score: {trial_fbeta}\")\n",
    "\n",
    "        if trial.number % 100 == 0:  # Slack message every 100 trials to avoid spamming\n",
    "            message = f\"Trial {trial.number} completed with average F0.5 Score: {trial_fbeta}\"\n",
    "            if self.slack_channel:\n",
    "                send_slack_message(self.slack_channel, message)\n",
    "\n",
    "        return trial_fbeta\n",
    "\n",
    "    def train_and_evaluate(self) -> pd.DataFrame:\n",
    "        ordered_datasets = ['30_day_data', '60_day_data', '90_day_data', 'full_data']\n",
    "\n",
    "        # Create study once, not repeatedly\n",
    "        study_f0_5 = optuna.create_study(direction='maximize')\n",
    "\n",
    "        for truncation_label in ordered_datasets:\n",
    "            dataset = self.datasets[truncation_label]\n",
    "            X, y = dataset['train'].drop(columns=['merged_category'], errors='ignore'), dataset['train']['merged_category']\n",
    "            self.accumulated_X = pd.concat([self.accumulated_X, X], ignore_index=True)\n",
    "            self.accumulated_y = pd.concat([self.accumulated_y, y], ignore_index=True)\n",
    "\n",
    "            if truncation_label not in self.best_params:\n",
    "                # Optimize on the same study\n",
    "                study_f0_5.optimize(self.objective_f0_5, n_trials=1000, n_jobs=1)\n",
    "                best_params_f0_5 = study_f0_5.best_trial.params\n",
    "                self.best_params[f\"{truncation_label}_f0_5\"] = best_params_f0_5\n",
    "                self.save_best_params()\n",
    "\n",
    "            self.fit_and_save_model(truncation_label, X, y)\n",
    "            self.calculate_shap_values_for_model(truncation_label)\n",
    "\n",
    "        self.save_shap_values()\n",
    "        return self.summarize_metrics()\n",
    "\n",
    "    def fit_and_save_model(self, truncation_label: str, X: pd.DataFrame, y: pd.Series):\n",
    "        best_params_f0_5 = self.best_params[f\"{truncation_label}_f0_5\"]\n",
    "        model_f0_5 = XGBClassifier(**self._build_model_params(best_params_f0_5))\n",
    "        self.fit_model_and_save(model_f0_5, X, y, f\"{truncation_label}_f0_5\")\n",
    "\n",
    "    def fit_model_and_save(self, model, X: pd.DataFrame, y: pd.Series, model_key: str):\n",
    "        if model_key not in self.best_params:\n",
    "            raise ValueError(f\"Best parameters for model {model_key} not found.\")\n",
    "        \n",
    "        kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Split the training data further into training and validation sets\n",
    "            X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Fit the model with validation set\n",
    "            model.fit(\n",
    "                X_train_split, \n",
    "                y_train_split, \n",
    "                eval_set=[(X_val_split, y_val_split)],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict_proba(X_test)[:, 1]  # Predict probabilities for the positive class\n",
    "\n",
    "            # Get the threshold from best_params\n",
    "            threshold = self.best_params[model_key]['threshold']\n",
    "\n",
    "            # Compute metrics using the threshold from best_params\n",
    "            metrics = self.compute_metrics(y_test, y_pred, threshold)\n",
    "            self.model_results[model_key] = model\n",
    "\n",
    "        self.save_model(model, model_key)\n",
    "\n",
    "    def calculate_shap_values_for_model(self, truncation_label: str):\n",
    "        model = self.model_results[f\"{truncation_label}_f0_5\"]\n",
    "        X_test = self.accumulated_X\n",
    "\n",
    "        # SHAP value calculation (keeping your original approach)\n",
    "        self.calculate_shap_values(model, X_test, truncation_label, 'f0_5')\n",
    "\n",
    "    def calculate_shap_values(self, model: XGBClassifier, X: pd.DataFrame, truncation_label: str, model_type: str):\n",
    "        explainer = shap.Explainer(model)\n",
    "        shap_values = explainer(X)\n",
    "        self.shap_values_dict[f\"{truncation_label}_{model_type}\"] = {\n",
    "            'shap_values': shap_values.values.tolist(),\n",
    "            'feature_names': X.columns.tolist()\n",
    "        }\n",
    "\n",
    "    def _build_model_params(self, params: dict) -> dict:\n",
    "        return {\n",
    "            'learning_rate': params['xgb_learning_rate'],\n",
    "            'n_estimators': params['xgb_n_estimators'],\n",
    "            'max_depth': params['xgb_max_depth'],\n",
    "            'subsample': params['xgb_subsample'],\n",
    "            'colsample_bytree': params['xgb_colsample_bytree'],\n",
    "            'reg_alpha': params['xgb_reg_alpha'],\n",
    "            'reg_lambda': params['xgb_reg_lambda'],\n",
    "            'tree_method': 'hist',\n",
    "            'device': 'cuda',\n",
    "            'early_stopping_rounds': 50\n",
    "        }\n",
    "\n",
    "    def save_best_params(self):\n",
    "        with open(self.config_file, 'w') as f:\n",
    "            json.dump(self.best_params, f)\n",
    "\n",
    "    def save_model(self, model: XGBClassifier, model_key: str):\n",
    "        joblib.dump(model, f\"{self.model_dir}/{model_key}.joblib\")\n",
    "        \n",
    "    def save_shap_values(self):\n",
    "        # Save SHAP values to a JSON file\n",
    "        shap_values_path = os.path.join(self.model_dir, 'shap_values.json')\n",
    "        with open(shap_values_path, 'w') as f:\n",
    "            json.dump(self.shap_values_dict, f)\n",
    "        logging.info(f\"SHAP values saved to {shap_values_path}\")\n",
    "\n",
    "    def summarize_metrics(self):\n",
    "        summary_data = []\n",
    "        for key, model in self.model_results.items():\n",
    "            truncation_label = key.split('_')[0]\n",
    "            # Model prediction to compute metrics\n",
    "            y_pred = model.predict_proba(self.accumulated_X)[:, 1]\n",
    "            metrics = self.compute_metrics(self.accumulated_y, y_pred, self.best_params[key]['threshold'])\n",
    "            summary_data.append({\n",
    "                'Model': key,\n",
    "                'Truncation_Label': truncation_label,\n",
    "                'Accuracy': metrics.get('Accuracy'),\n",
    "                'Precision': metrics.get('Precision'),\n",
    "                'Recall': metrics.get('Recall'),\n",
    "                'F0.5 Score': metrics.get('F0.5 Score'),\n",
    "            })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_csv(os.path.join(self.model_dir, 'summary_metrics.csv'), index=False)\n",
    "        return summary_df\n",
    "\n",
    "    def evaluate_on_holdout(self, df_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        if df_test.empty:\n",
    "            logging.warning(\"The test DataFrame is empty.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Prepare test data\n",
    "        X_test = df_test.drop(columns=['merged_category'], errors='ignore')\n",
    "        y_test = df_test['merged_category']\n",
    "\n",
    "        if X_test.empty or y_test.empty:\n",
    "            logging.warning(\"X_test or y_test is empty after dropping columns.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        if not self.model_results:\n",
    "            logging.warning(\"No models found in self.model_results.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        holdout_metrics = {}\n",
    "\n",
    "        for model_key, model in self.model_results.items():\n",
    "            # Predict probabilities for positive class\n",
    "            y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # Retrieve threshold for the model\n",
    "            threshold = self.best_params[model_key]['threshold']\n",
    "\n",
    "            # Compute metrics\n",
    "            metrics = self.compute_metrics(y_test, y_pred, threshold)\n",
    "            holdout_metrics[model_key] = metrics\n",
    "\n",
    "        # Convert metrics to DataFrame and save\n",
    "        results_df = pd.DataFrame.from_dict(holdout_metrics, orient='index')\n",
    "        results_df.to_csv(os.path.join(self.model_dir, 'holdout_results.csv'), index=False)\n",
    "\n",
    "        if not results_df.empty:\n",
    "            logging.info(\"Holdout evaluation completed successfully.\")\n",
    "            if self.slack_channel:\n",
    "                send_slack_message(self.slack_channel, \"Holdout evaluation completed successfully.\")\n",
    "\n",
    "        return results_df\n",
    "\n",
    "\n",
    "# SHAP functions\n",
    "def average_shap_values(shap_values_dict):\n",
    "    average_shap_values_dict = {}\n",
    "    for truncation_label, shap_info in shap_values_dict.items():\n",
    "        shap_vals = np.array(shap_info['shap_values'])\n",
    "        avg_shap_vals = np.mean(np.abs(shap_vals), axis=(0, 2)) if shap_vals.ndim == 3 else np.mean(np.abs(shap_vals), axis=0)\n",
    "        print(f\"SHAP values shape for {truncation_label}: {shap_vals.shape}\")\n",
    "        print(f\"Averaged SHAP values shape for {truncation_label}: {avg_shap_vals.shape}\")\n",
    "        truncation_label_simplified = \"_\".join(truncation_label.split(\"_\")[:-1])\n",
    "        if truncation_label_simplified in average_shap_values_dict:\n",
    "            average_shap_values_dict[truncation_label_simplified].append(avg_shap_vals)\n",
    "        else:\n",
    "            average_shap_values_dict[truncation_label_simplified] = [avg_shap_vals]\n",
    "    return average_shap_values_dict\n",
    "\n",
    "def combine_and_average_shap_values(average_shap_values_dict, feature_names):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for truncation_label, avg_shap_vals_list in average_shap_values_dict.items():\n",
    "        avg_shap_vals_across_models = np.mean(avg_shap_vals_list, axis=0)\n",
    "        print(f\"Processing {truncation_label}:\")\n",
    "        print(f\" - Averaged SHAP values shape across models: {avg_shap_vals_across_models.shape}\")\n",
    "        print(f\" - Feature names length: {len(feature_names)}\")\n",
    "        if len(avg_shap_vals_across_models) != len(feature_names):\n",
    "            print(f\"Length mismatch for {truncation_label}: {len(avg_shap_vals_across_models)} SHAP values vs {len(feature_names)} features\")\n",
    "            continue\n",
    "        truncation_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Mean SHAP Value': avg_shap_vals_across_models,\n",
    "            'Truncation Label': truncation_label\n",
    "        })\n",
    "        combined_df = pd.concat([combined_df, truncation_df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "def plot_combined_shap_values(combined_df):\n",
    "    mean_shap_values = combined_df.groupby('Feature')['Mean SHAP Value'].mean().sort_values(ascending=False).reset_index()\n",
    "    mean_shap_values = mean_shap_values[::-1]\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    for label in combined_df['Truncation Label'].unique():\n",
    "        subset = combined_df[combined_df['Truncation Label'] == label]\n",
    "        subset_sorted = subset.set_index('Feature').loc[mean_shap_values['Feature']].reset_index()\n",
    "        plt.scatter(subset_sorted['Mean SHAP Value'], subset_sorted['Feature'], label=label, alpha=0.7, s=100)\n",
    "    \n",
    "    plt.xlabel('Mean SHAP Value')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Average SHAP Values for Different Truncation Labels')\n",
    "    plt.legend(title='Truncation Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score, accuracy_score, precision_score, recall_score,\n",
    "    fbeta_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def send_slack_message(channel_id, message):\n",
    "    client = WebClient(token=os.environ['SLACK_BOT_TOKEN'])\n",
    "    try:\n",
    "        response = client.chat_postMessage(channel=channel_id, text=message)\n",
    "        logging.info(f\"Message sent to channel {channel_id}: {response['message']['text']}\")\n",
    "    except SlackApiError as e:\n",
    "        logging.error(f\"Error posting message: {e.response['error']}\")\n",
    "\n",
    "class XGBoostPredictor:\n",
    "    def __init__(self, datasets, model_configs, config_file='best_config.json', model_dir='models', slack_channel=None):\n",
    "        self.datasets = datasets\n",
    "        self.model_configs = model_configs\n",
    "        self.config_file = config_file\n",
    "        self.model_dir = model_dir\n",
    "        self.slack_channel = slack_channel\n",
    "        self.model_results = {}\n",
    "        self.ensemble_results = {}\n",
    "        self.best_params = {}\n",
    "        self.accumulated_X = pd.DataFrame()\n",
    "        self.accumulated_y = pd.Series(dtype=float)\n",
    "        self.shap_values_dict = {}\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "\n",
    "        # Ensure a fresh start by removing existing best parameters file if it exists\n",
    "        if os.path.exists(config_file):\n",
    "            os.remove(config_file)\n",
    "\n",
    "    def compute_metrics(self, y_true, y_pred, threshold):\n",
    "        y_true_binary = (y_true >= threshold).astype(int)\n",
    "        y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "        metrics = {\n",
    "            'Mean Squared Error': mean_squared_error(y_true, y_pred),\n",
    "            'R^2 Score': r2_score(y_true, y_pred),\n",
    "            'Accuracy': accuracy_score(y_true_binary, y_pred_binary),\n",
    "            'Precision': precision_score(y_true_binary, y_pred_binary, average='binary', zero_division=0),\n",
    "            'Recall': recall_score(y_true_binary, y_pred_binary, average='binary', zero_division=0),\n",
    "            'F0.5 Score': fbeta_score(y_true_binary, y_pred_binary, beta=1, average='binary', zero_division=0),\n",
    "            'ROC AUC': roc_auc_score(y_true_binary, y_pred_binary)\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    def objective_f0_5(self, trial):\n",
    "        logging.info(f\"Starting trial {trial.number} for F0.5 optimization\")\n",
    "\n",
    "        xgb_params = {\n",
    "            'learning_rate': trial.suggest_float('xgb_learning_rate', 1e-4, 1e-1, log=True),\n",
    "            'n_estimators': trial.suggest_int('xgb_n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('xgb_max_depth', 3, 12),\n",
    "            'subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('xgb_reg_alpha', 1e-8, 1.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('xgb_reg_lambda', 1e-8, 1.0, log=True),\n",
    "            'tree_method': 'hist',\n",
    "            'device': 'cuda',\n",
    "            'early_stopping_rounds': 50\n",
    "        }\n",
    "\n",
    "        threshold = trial.suggest_float('threshold', 0.1, 0.9)\n",
    "\n",
    "        outer_kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        outer_fold_metrics = []\n",
    "\n",
    "        for train_index, test_index in outer_kf.split(self.accumulated_X):\n",
    "            X_train, X_test = self.accumulated_X.iloc[train_index], self.accumulated_X.iloc[test_index]\n",
    "            y_train, y_test = self.accumulated_y.iloc[train_index], self.accumulated_y.iloc[test_index]\n",
    "\n",
    "            inner_kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "            inner_fold_metrics = []\n",
    "\n",
    "            for inner_train_index, val_index in inner_kf.split(X_train):\n",
    "                X_inner_train, X_val = X_train.iloc[inner_train_index], X_train.iloc[val_index]\n",
    "                y_inner_train, y_val = y_train.iloc[inner_train_index], y_train.iloc[val_index]\n",
    "\n",
    "                model = XGBRegressor(**xgb_params)\n",
    "                model.fit(X_inner_train, y_inner_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "                y_val_pred = model.predict(X_val)\n",
    "                metrics = self.compute_metrics(y_val, y_val_pred, threshold)\n",
    "                inner_fold_metrics.append(metrics)\n",
    "\n",
    "            avg_fbeta = np.nanmean([fm['F0.5 Score'] for fm in inner_fold_metrics if fm['F0.5 Score'] is not None])\n",
    "            outer_fold_metrics.append(avg_fbeta)\n",
    "\n",
    "        trial_fbeta = np.mean(outer_fold_metrics)\n",
    "        logging.info(f\"Trial {trial.number} completed with average F0.5 Score: {trial_fbeta}\")\n",
    "\n",
    "        if trial.number % 10 == 0:\n",
    "            message = f\"Trial {trial.number} completed with average F0.5 Score: {trial_fbeta}\"\n",
    "            if self.slack_channel:\n",
    "                send_slack_message(self.slack_channel, message)\n",
    "\n",
    "        return trial_fbeta\n",
    "\n",
    "    def objective_roc_auc(self, trial):\n",
    "        logging.info(f\"Starting trial {trial.number} for ROC AUC optimization\")\n",
    "\n",
    "        xgb_params = {\n",
    "            'learning_rate': trial.suggest_float('xgb_learning_rate', 1e-4, 1e-1, log=True),\n",
    "            'n_estimators': trial.suggest_int('xgb_n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('xgb_max_depth', 3, 12),\n",
    "            'subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('xgb_reg_alpha', 1e-8, 1.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('xgb_reg_lambda', 1e-8, 1.0, log=True),\n",
    "            'tree_method': 'hist',\n",
    "            'device': 'cuda',\n",
    "            'early_stopping_rounds': 50\n",
    "        }\n",
    "\n",
    "        threshold = trial.suggest_float('threshold', 0.1, 0.9)\n",
    "\n",
    "        outer_kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        outer_fold_metrics = []\n",
    "\n",
    "        for train_index, test_index in outer_kf.split(self.accumulated_X):\n",
    "            X_train, X_test = self.accumulated_X.iloc[train_index], self.accumulated_X.iloc[test_index]\n",
    "            y_train, y_test = self.accumulated_y.iloc[train_index], self.accumulated_y.iloc[test_index]\n",
    "\n",
    "            inner_kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "            inner_fold_metrics = []\n",
    "\n",
    "            for inner_train_index, val_index in inner_kf.split(X_train):\n",
    "                X_inner_train, X_val = X_train.iloc[inner_train_index], X_train.iloc[val_index]\n",
    "                y_inner_train, y_val = y_train.iloc[inner_train_index], y_train.iloc[val_index]\n",
    "\n",
    "                model = XGBRegressor(**xgb_params)\n",
    "                model.fit(X_inner_train, y_inner_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "                y_val_pred = model.predict(X_val)\n",
    "                metrics = self.compute_metrics(y_val, y_val_pred, threshold)\n",
    "                inner_fold_metrics.append(metrics)\n",
    "\n",
    "            avg_roc_auc = np.nanmean([fm['ROC AUC'] for fm in inner_fold_metrics if fm['ROC AUC'] is not None])\n",
    "            outer_fold_metrics.append(avg_roc_auc)\n",
    "\n",
    "        trial_roc_auc = np.mean(outer_fold_metrics)\n",
    "        logging.info(f\"Trial {trial.number} completed with average ROC AUC: {trial_roc_auc}\")\n",
    "\n",
    "        if trial.number % 10 == 0:\n",
    "            message = f\"Trial {trial.number} completed with average ROC AUC: {trial_roc_auc}\"\n",
    "            if self.slack_channel:\n",
    "                send_slack_message(self.slack_channel, message)\n",
    "\n",
    "        return trial_roc_auc\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        ordered_datasets = ['30_day_data', '60_day_data', '90_day_data', 'full_data']\n",
    "\n",
    "        for truncation_label in ordered_datasets:\n",
    "            dataset = self.datasets[truncation_label]\n",
    "            X = dataset['train'].drop(columns=['merged_category'], errors='ignore')\n",
    "            y = dataset['train']['merged_category']\n",
    "\n",
    "            self.accumulated_X = pd.concat([self.accumulated_X, X], ignore_index=True)\n",
    "            self.accumulated_y = pd.concat([self.accumulated_y, y], ignore_index=True)\n",
    "\n",
    "            if truncation_label not in self.best_params:\n",
    "                # Optimize for F0.5 Score\n",
    "                study_f0_5 = optuna.create_study(direction='maximize')\n",
    "                study_f0_5.optimize(self.objective_f0_5, n_trials=1000, n_jobs=1)  # Limit to 1 job to avoid concurrent GPU issues\n",
    "                best_trial_f0_5 = study_f0_5.best_trial\n",
    "                best_params_f0_5 = best_trial_f0_5.params\n",
    "                self.best_params[f\"{truncation_label}_f0_5\"] = best_params_f0_5\n",
    "\n",
    "                # Optimize for ROC AUC\n",
    "                study_roc_auc = optuna.create_study(direction='maximize')\n",
    "                study_roc_auc.optimize(self.objective_roc_auc, n_trials=1000, n_jobs=1)  # Limit to 1 job to avoid concurrent GPU issues\n",
    "                best_trial_roc_auc = study_roc_auc.best_trial\n",
    "                best_params_roc_auc = best_trial_roc_auc.params\n",
    "                self.best_params[f\"{truncation_label}_roc_auc\"] = best_params_roc_auc\n",
    "\n",
    "                self.save_best_params()\n",
    "\n",
    "            best_params_f0_5 = self.best_params[f\"{truncation_label}_f0_5\"]\n",
    "            logging.info(f\"Best trial params for {truncation_label} F0.5: {best_params_f0_5}\")\n",
    "\n",
    "            best_params_roc_auc = self.best_params[f\"{truncation_label}_roc_auc\"]\n",
    "            logging.info(f\"Best trial params for {truncation_label} ROC AUC: {best_params_roc_auc}\")\n",
    "\n",
    "            model_f0_5 = XGBRegressor(\n",
    "                learning_rate=best_params_f0_5['xgb_learning_rate'],\n",
    "                n_estimators=best_params_f0_5['xgb_n_estimators'],\n",
    "                max_depth=best_params_f0_5['xgb_max_depth'],\n",
    "                subsample=best_params_f0_5['xgb_subsample'],\n",
    "                colsample_bytree=best_params_f0_5['xgb_colsample_bytree'],\n",
    "                reg_alpha=best_params_f0_5['xgb_reg_alpha'],\n",
    "                reg_lambda=best_params_f0_5['xgb_reg_lambda'],\n",
    "                tree_method='hist',\n",
    "                device='cuda',\n",
    "                early_stopping_rounds=50\n",
    "            )\n",
    "            threshold_f0_5 = best_params_f0_5['threshold']\n",
    "\n",
    "            model_roc_auc = XGBRegressor(\n",
    "                learning_rate=best_params_roc_auc['xgb_learning_rate'],\n",
    "                n_estimators=best_params_roc_auc['xgb_n_estimators'],\n",
    "                max_depth=best_params_roc_auc['xgb_max_depth'],\n",
    "                subsample=best_params_roc_auc['xgb_subsample'],\n",
    "                colsample_bytree=best_params_roc_auc['xgb_colsample_bytree'],\n",
    "                reg_alpha=best_params_roc_auc['xgb_reg_alpha'],\n",
    "                reg_lambda=best_params_roc_auc['xgb_reg_lambda'],\n",
    "                tree_method='hist',\n",
    "                device='cuda',\n",
    "                early_stopping_rounds=50\n",
    "            )\n",
    "            threshold_roc_auc = best_params_roc_auc['threshold']\n",
    "\n",
    "            kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "            fold_metrics_f0_5 = []\n",
    "            fold_metrics_roc_auc = []\n",
    "\n",
    "            for train_index, test_index in kf.split(self.accumulated_X):\n",
    "                X_train, X_test = self.accumulated_X.iloc[train_index], self.accumulated_X.iloc[test_index]\n",
    "                y_train, y_test = self.accumulated_y.iloc[train_index], self.accumulated_y.iloc[test_index]\n",
    "\n",
    "                X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "                model_f0_5.fit(X_train_split, y_train_split, eval_set=[(X_val_split, y_val_split)], verbose=False)\n",
    "                y_pred_f0_5 = model_f0_5.predict(X_test)\n",
    "                metrics_f0_5 = self.compute_metrics(y_test, y_pred_f0_5, threshold_f0_5)\n",
    "                fold_metrics_f0_5.append(metrics_f0_5)\n",
    "\n",
    "                model_roc_auc.fit(X_train_split, y_train_split, eval_set=[(X_val_split, y_val_split)], verbose=False)\n",
    "                y_pred_roc_auc = model_roc_auc.predict(X_test)\n",
    "                metrics_roc_auc = self.compute_metrics(y_test, y_pred_roc_auc, threshold_roc_auc)\n",
    "                fold_metrics_roc_auc.append(metrics_roc_auc)\n",
    "\n",
    "                model_key_f0_5 = f\"{truncation_label}_xgboost_f0_5_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "                self.model_results[model_key_f0_5] = model_f0_5\n",
    "\n",
    "                model_key_roc_auc = f\"{truncation_label}_xgboost_roc_auc_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "                self.model_results[model_key_roc_auc] = model_roc_auc\n",
    "\n",
    "                self.save_model(model_f0_5, model_key_f0_5)\n",
    "                self.save_model(model_roc_auc, model_key_roc_auc)\n",
    "\n",
    "                # Calculate SHAP values for feature importance\n",
    "                self.calculate_shap_values(model_f0_5, X_test, truncation_label, 'f0_5')\n",
    "                self.calculate_shap_values(model_roc_auc, X_test, truncation_label, 'roc_auc')\n",
    "\n",
    "            avg_metrics_f0_5 = {key: np.nanmean([fm[key] for fm in fold_metrics_f0_5 if fm[key] is not None]) for key in fold_metrics_f0_5[0]}\n",
    "            self.ensemble_results[f\"{truncation_label}_ensemble_f0_5\"] = avg_metrics_f0_5\n",
    "\n",
    "            avg_metrics_roc_auc = {key: np.nanmean([fm[key] for fm in fold_metrics_roc_auc if fm[key] is not None]) for key in fold_metrics_roc_auc[0]}\n",
    "            self.ensemble_results[f\"{truncation_label}_ensemble_roc_auc\"] = avg_metrics_roc_auc\n",
    "\n",
    "            if self.slack_channel:\n",
    "                send_slack_message(self.slack_channel, f\"Training completed for {truncation_label}\")\n",
    "\n",
    "        self.save_shap_values()\n",
    "        return self.summarize_metrics()\n",
    "\n",
    "    def calculate_shap_values(self, model, X, truncation_label, model_type):\n",
    "        explainer = shap.Explainer(model)\n",
    "        shap_values = explainer(X)\n",
    "        self.shap_values_dict[f\"{truncation_label}_{model_type}\"] = {\n",
    "            'shap_values': shap_values.values.tolist(),  # Convert ndarray to list\n",
    "            'feature_names': X.columns.tolist()\n",
    "        }\n",
    "\n",
    "    def save_shap_values(self):\n",
    "        with open(os.path.join(self.model_dir, 'shap_values.json'), 'w') as f:\n",
    "            json.dump(self.shap_values_dict, f)\n",
    "\n",
    "    def summarize_metrics(self):\n",
    "        summary_data = []\n",
    "        for key, metrics in self.ensemble_results.items():\n",
    "            truncation_label, _ = key.rsplit('_', 1)\n",
    "            model_type = truncation_label.split('_')[0]\n",
    "\n",
    "            summary_data.append({\n",
    "                'Model': model_type,\n",
    "                'Truncation_Label': truncation_label,\n",
    "                'Mean Squared Error': metrics.get('Mean Squared Error'),\n",
    "                'R^2 Score': metrics.get('R^2 Score'),\n",
    "                'Accuracy': metrics.get('Accuracy'),\n",
    "                'Precision': metrics.get('Precision'),\n",
    "                'Recall': metrics.get('Recall'),\n",
    "                'F0.5 Score': metrics.get('F0.5 Score'),\n",
    "                'ROC AUC': metrics.get('ROC AUC')\n",
    "            })\n",
    "\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_csv(os.path.join(self.model_dir, 'summary_metrics.csv'), index=False)\n",
    "        return summary_df[['Model', 'Truncation_Label', 'Mean Squared Error', 'R^2 Score', 'Accuracy', 'Precision', 'Recall', 'F0.5 Score', 'ROC AUC']]\n",
    "\n",
    "    def evaluate_on_holdout(self, df_test):\n",
    "        if df_test.empty:\n",
    "            logging.warning(\"The test DataFrame is empty.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        X_test = df_test.drop(columns=['merged_category'], errors='ignore')\n",
    "        y_test = df_test['merged_category']\n",
    "\n",
    "        if X_test.empty or y_test.empty:\n",
    "            logging.warning(\"X_test or y_test is empty after dropping columns.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        if not self.model_results:\n",
    "            logging.warning(\"No models found in self.model_results.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        holdout_ensemble_results = {}\n",
    "\n",
    "        for truncation_label, best_params in self.best_params.items():\n",
    "            model = XGBRegressor(\n",
    "                learning_rate=best_params['xgb_learning_rate'],\n",
    "                n_estimators=best_params['xgb_n_estimators'],\n",
    "                max_depth=best_params['xgb_max_depth'],\n",
    "                subsample=best_params['xgb_subsample'],\n",
    "                colsample_bytree=best_params['xgb_colsample_bytree'],\n",
    "                reg_alpha=best_params['xgb_reg_alpha'],\n",
    "                reg_lambda=best_params['xgb_reg_lambda'],\n",
    "                tree_method='hist',\n",
    "                device='cuda'\n",
    "            )\n",
    "            threshold = best_params['threshold']\n",
    "\n",
    "            X_train_all = self.accumulated_X\n",
    "            y_train_all = self.accumulated_y\n",
    "\n",
    "            model.fit(X_train_all, y_train_all)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            metrics = self.compute_metrics(y_test, y_pred, threshold)\n",
    "            holdout_ensemble_results[truncation_label] = metrics\n",
    "\n",
    "            self.plot_confusion_matrix(y_test, y_pred, threshold)\n",
    "\n",
    "        results_df = pd.DataFrame.from_dict(holdout_ensemble_results, orient='index')\n",
    "        results_df.to_csv(os.path.join(self.model_dir, 'holdout_results.csv'), index=False)\n",
    "\n",
    "        if not results_df.empty:\n",
    "            logging.info(\"Holdout evaluation completed successfully.\")\n",
    "            if self.slack_channel:\n",
    "                send_slack_message(self.slack_channel, \"Holdout evaluation completed successfully.\")\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred, threshold):\n",
    "        y_true_binary = (y_true >= threshold).astype(int)\n",
    "        y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "        cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    def save_best_params(self):\n",
    "        with open(self.config_file, 'w') as f:\n",
    "            json.dump(self.best_params, f)\n",
    "\n",
    "    def save_model(self, model, model_key):\n",
    "        joblib.dump(model, f\"{self.model_dir}/{model_key}.joblib\")\n",
    "\n",
    "# SHAP functions\n",
    "def average_shap_values(shap_values_dict):\n",
    "    average_shap_values_dict = {}\n",
    "    for truncation_label, shap_info in shap_values_dict.items():\n",
    "        shap_vals = np.array(shap_info['shap_values'])\n",
    "        avg_shap_vals = np.mean(np.abs(shap_vals), axis=(0, 2)) if shap_vals.ndim == 3 else np.mean(np.abs(shap_vals), axis=0)\n",
    "        print(f\"SHAP values shape for {truncation_label}: {shap_vals.shape}\")\n",
    "        print(f\"Averaged SHAP values shape for {truncation_label}: {avg_shap_vals.shape}\")\n",
    "        truncation_label_simplified = \"_\".join(truncation_label.split(\"_\")[:-1])\n",
    "        if truncation_label_simplified in average_shap_values_dict:\n",
    "            average_shap_values_dict[truncation_label_simplified].append(avg_shap_vals)\n",
    "        else:\n",
    "            average_shap_values_dict[truncation_label_simplified] = [avg_shap_vals]\n",
    "    return average_shap_values_dict\n",
    "\n",
    "def combine_and_average_shap_values(average_shap_values_dict, feature_names):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for truncation_label, avg_shap_vals_list in average_shap_values_dict.items():\n",
    "        avg_shap_vals_across_models = np.mean(avg_shap_vals_list, axis=0)\n",
    "        print(f\"Processing {truncation_label}:\")\n",
    "        print(f\" - Averaged SHAP values shape across models: {avg_shap_vals_across_models.shape}\")\n",
    "        print(f\" - Feature names length: {len(feature_names)}\")\n",
    "        if len(avg_shap_vals_across_models) != len(feature_names):\n",
    "            print(f\"Length mismatch for {truncation_label}: {len(avg_shap_vals_across_models)} SHAP values vs {len(feature_names)} features\")\n",
    "            continue\n",
    "        truncation_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Mean SHAP Value': avg_shap_vals_across_models,\n",
    "            'Truncation Label': truncation_label\n",
    "        })\n",
    "        combined_df = pd.concat([combined_df, truncation_df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "def plot_combined_shap_values(combined_df):\n",
    "    mean_shap_values = combined_df.groupby('Feature')['Mean SHAP Value'].mean().sort_values(ascending=False).reset_index()\n",
    "    mean_shap_values = mean_shap_values[::-1]\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    for label in combined_df['Truncation Label'].unique():\n",
    "        subset = combined_df[combined_df['Truncation Label'] == label]\n",
    "        subset_sorted = subset.set_index('Feature').loc[mean_shap_values['Feature']].reset_index()\n",
    "        plt.scatter(subset_sorted['Mean SHAP Value'], subset_sorted['Feature'], label=label, alpha=0.7, s=100)\n",
    "    \n",
    "    plt.xlabel('Mean SHAP Value')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Average SHAP Values for Different Truncation Labels')\n",
    "    plt.legend(title='Truncation Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-02 14:02:32,518] A new study created in memory with name: no-name-323936ac-68f6-4ec7-b225-631470000905\n",
      "INFO:root:Starting trial 0 for F0.5 optimization\n",
      "INFO:root:Starting trial 0 for F0.5 optimization\n",
      "INFO:root:Trial 0 completed with average F0.5 Score: 0.6798340377253819\n",
      "INFO:root:Message sent to channel #hyperparametertuning: Trial 0 completed with average F0.5 Score: 0.6798340377253819\n",
      "[I 2024-10-02 14:02:42,431] Trial 0 finished with value: 0.6798340377253819 and parameters: {'xgb_learning_rate': 0.04278396659243537, 'xgb_n_estimators': 320, 'xgb_max_depth': 9, 'xgb_subsample': 0.7502537919859544, 'xgb_colsample_bytree': 0.8117109216461992, 'xgb_reg_alpha': 5.319909976751335e-08, 'xgb_reg_lambda': 0.0006701803741664304, 'threshold': 0.46661483157409867}. Best is trial 0 with value: 0.6798340377253819.\n",
      "INFO:root:Starting trial 1 for F0.5 optimization\n",
      "INFO:root:Trial 1 completed with average F0.5 Score: 0.5817754555440829\n",
      "[I 2024-10-02 14:02:51,449] Trial 1 finished with value: 0.5817754555440829 and parameters: {'xgb_learning_rate': 0.00800557473094062, 'xgb_n_estimators': 178, 'xgb_max_depth': 6, 'xgb_subsample': 0.5393667106648572, 'xgb_colsample_bytree': 0.9070179306666828, 'xgb_reg_alpha': 6.670572234064391e-08, 'xgb_reg_lambda': 1.979312621216827e-06, 'threshold': 0.23438008053430368}. Best is trial 0 with value: 0.6798340377253819.\n",
      "INFO:root:Starting trial 2 for F0.5 optimization\n",
      "INFO:root:Trial 2 completed with average F0.5 Score: 0.573001478524658\n",
      "[I 2024-10-02 14:03:08,511] Trial 2 finished with value: 0.573001478524658 and parameters: {'xgb_learning_rate': 0.00015167747300054237, 'xgb_n_estimators': 141, 'xgb_max_depth': 12, 'xgb_subsample': 0.8449931452503685, 'xgb_colsample_bytree': 0.526901199239301, 'xgb_reg_alpha': 1.267888192260228e-06, 'xgb_reg_lambda': 1.831715701794421e-05, 'threshold': 0.17422327332023882}. Best is trial 0 with value: 0.6798340377253819.\n",
      "INFO:root:Starting trial 3 for F0.5 optimization\n",
      "INFO:root:Trial 3 completed with average F0.5 Score: 0.6326310748364753\n",
      "[I 2024-10-02 14:03:27,768] Trial 3 finished with value: 0.6326310748364753 and parameters: {'xgb_learning_rate': 0.0029384391731752876, 'xgb_n_estimators': 328, 'xgb_max_depth': 8, 'xgb_subsample': 0.6906141093741356, 'xgb_colsample_bytree': 0.6794468415286514, 'xgb_reg_alpha': 0.04004917951209147, 'xgb_reg_lambda': 0.0009976096654306594, 'threshold': 0.4067098823099725}. Best is trial 0 with value: 0.6798340377253819.\n",
      "INFO:root:Starting trial 4 for F0.5 optimization\n",
      "INFO:root:Trial 4 completed with average F0.5 Score: 0.6529441286584357\n",
      "[I 2024-10-02 14:03:45,332] Trial 4 finished with value: 0.6529441286584357 and parameters: {'xgb_learning_rate': 0.002947231460630933, 'xgb_n_estimators': 236, 'xgb_max_depth': 9, 'xgb_subsample': 0.7499442831157637, 'xgb_colsample_bytree': 0.5778047524595571, 'xgb_reg_alpha': 5.327684151731057e-05, 'xgb_reg_lambda': 1.991962229700587e-06, 'threshold': 0.5769430267196504}. Best is trial 0 with value: 0.6798340377253819.\n",
      "INFO:root:Starting trial 5 for F0.5 optimization\n",
      "INFO:root:Trial 5 completed with average F0.5 Score: 0.15494545768823792\n",
      "[I 2024-10-02 14:04:03,161] Trial 5 finished with value: 0.15494545768823792 and parameters: {'xgb_learning_rate': 0.0007504821187739221, 'xgb_n_estimators': 433, 'xgb_max_depth': 4, 'xgb_subsample': 0.7523196218933693, 'xgb_colsample_bytree': 0.9170101571099392, 'xgb_reg_alpha': 0.08658830500686895, 'xgb_reg_lambda': 4.783945896319932e-07, 'threshold': 0.5960862533794085}. Best is trial 0 with value: 0.6798340377253819.\n",
      "INFO:root:Starting trial 6 for F0.5 optimization\n",
      "INFO:root:Trial 6 completed with average F0.5 Score: 0.0\n",
      "[I 2024-10-02 14:04:25,920] Trial 6 finished with value: 0.0 and parameters: {'xgb_learning_rate': 0.0003263308682532312, 'xgb_n_estimators': 317, 'xgb_max_depth': 9, 'xgb_subsample': 0.5972609653417744, 'xgb_colsample_bytree': 0.7704542577298076, 'xgb_reg_alpha': 8.118356161697734e-05, 'xgb_reg_lambda': 3.9071909282343775e-05, 'threshold': 0.7253588536295146}. Best is trial 0 with value: 0.6798340377253819.\n",
      "INFO:root:Starting trial 7 for F0.5 optimization\n",
      "INFO:root:Trial 7 completed with average F0.5 Score: 0.573001478524658\n",
      "[I 2024-10-02 14:04:31,954] Trial 7 finished with value: 0.573001478524658 and parameters: {'xgb_learning_rate': 0.00013470130576442475, 'xgb_n_estimators': 165, 'xgb_max_depth': 3, 'xgb_subsample': 0.6821538234110482, 'xgb_colsample_bytree': 0.9831565576190471, 'xgb_reg_alpha': 0.0004081407909344668, 'xgb_reg_lambda': 0.03963406806657443, 'threshold': 0.41043828589583176}. Best is trial 0 with value: 0.6798340377253819.\n",
      "INFO:root:Starting trial 8 for F0.5 optimization\n",
      "INFO:root:Trial 8 completed with average F0.5 Score: 0.573001478524658\n",
      "[I 2024-10-02 14:04:39,926] Trial 8 finished with value: 0.573001478524658 and parameters: {'xgb_learning_rate': 0.0024202237893687275, 'xgb_n_estimators': 83, 'xgb_max_depth': 10, 'xgb_subsample': 0.5110349123728583, 'xgb_colsample_bytree': 0.884686505067708, 'xgb_reg_alpha': 5.756342941556194e-07, 'xgb_reg_lambda': 1.231645055707556e-08, 'threshold': 0.32126751437541434}. Best is trial 0 with value: 0.6798340377253819.\n",
      "INFO:root:Starting trial 9 for F0.5 optimization\n",
      "INFO:root:Trial 9 completed with average F0.5 Score: 0.6844089766276609\n",
      "[I 2024-10-02 14:05:11,365] Trial 9 finished with value: 0.6844089766276609 and parameters: {'xgb_learning_rate': 0.009812734933863301, 'xgb_n_estimators': 431, 'xgb_max_depth': 12, 'xgb_subsample': 0.8561916228002043, 'xgb_colsample_bytree': 0.6782806963364773, 'xgb_reg_alpha': 0.022723105772181652, 'xgb_reg_lambda': 5.2310553878301523e-08, 'threshold': 0.5544443427569828}. Best is trial 9 with value: 0.6844089766276609.\n",
      "INFO:root:Starting trial 10 for F0.5 optimization\n",
      "INFO:root:Trial 10 completed with average F0.5 Score: 0.33205818783236296\n",
      "[I 2024-10-02 14:05:20,288] Trial 10 finished with value: 0.33205818783236296 and parameters: {'xgb_learning_rate': 0.07808437604546352, 'xgb_n_estimators': 490, 'xgb_max_depth': 12, 'xgb_subsample': 0.948929792686261, 'xgb_colsample_bytree': 0.6774791970558591, 'xgb_reg_alpha': 0.8882886607127649, 'xgb_reg_lambda': 3.306461521315979e-08, 'threshold': 0.8877535739570879}. Best is trial 9 with value: 0.6844089766276609.\n",
      "INFO:root:Starting trial 11 for F0.5 optimization\n",
      "INFO:root:Trial 11 completed with average F0.5 Score: 0.682353614032579\n",
      "[I 2024-10-02 14:05:34,733] Trial 11 finished with value: 0.682353614032579 and parameters: {'xgb_learning_rate': 0.026062837796810394, 'xgb_n_estimators': 396, 'xgb_max_depth': 11, 'xgb_subsample': 0.8677575371914551, 'xgb_colsample_bytree': 0.7903711348443707, 'xgb_reg_alpha': 1.930529486958243e-08, 'xgb_reg_lambda': 0.0007673037453536388, 'threshold': 0.49184177279355257}. Best is trial 9 with value: 0.6844089766276609.\n",
      "INFO:root:Starting trial 12 for F0.5 optimization\n",
      "INFO:root:Trial 12 completed with average F0.5 Score: 0.5862207417029687\n",
      "[I 2024-10-02 14:05:53,225] Trial 12 finished with value: 0.5862207417029687 and parameters: {'xgb_learning_rate': 0.01827735122636417, 'xgb_n_estimators': 402, 'xgb_max_depth': 11, 'xgb_subsample': 0.915244223830951, 'xgb_colsample_bytree': 0.7014488431664085, 'xgb_reg_alpha': 1.3329822357238331e-08, 'xgb_reg_lambda': 0.2611613196642489, 'threshold': 0.1053576222334277}. Best is trial 9 with value: 0.6844089766276609.\n",
      "INFO:root:Starting trial 13 for F0.5 optimization\n",
      "INFO:root:Trial 13 completed with average F0.5 Score: 0.6847980782452687\n",
      "[I 2024-10-02 14:06:14,224] Trial 13 finished with value: 0.6847980782452687 and parameters: {'xgb_learning_rate': 0.01463322171704438, 'xgb_n_estimators': 403, 'xgb_max_depth': 11, 'xgb_subsample': 0.9914287023828163, 'xgb_colsample_bytree': 0.7724210939390167, 'xgb_reg_alpha': 0.0020931573598179367, 'xgb_reg_lambda': 0.0016472599220492448, 'threshold': 0.5659843912535186}. Best is trial 13 with value: 0.6847980782452687.\n",
      "INFO:root:Starting trial 14 for F0.5 optimization\n",
      "INFO:root:Trial 14 completed with average F0.5 Score: 0.6606522846173741\n",
      "[I 2024-10-02 14:06:38,095] Trial 14 finished with value: 0.6606522846173741 and parameters: {'xgb_learning_rate': 0.010303625773519445, 'xgb_n_estimators': 496, 'xgb_max_depth': 6, 'xgb_subsample': 0.9959881529650876, 'xgb_colsample_bytree': 0.6142903611739068, 'xgb_reg_alpha': 0.002816634362016526, 'xgb_reg_lambda': 0.014345014532206423, 'threshold': 0.6272606789648016}. Best is trial 13 with value: 0.6847980782452687.\n",
      "INFO:root:Starting trial 15 for F0.5 optimization\n",
      "INFO:root:Trial 15 completed with average F0.5 Score: 0.6619438469833945\n",
      "[I 2024-10-02 14:07:16,277] Trial 15 finished with value: 0.6619438469833945 and parameters: {'xgb_learning_rate': 0.00761392383074767, 'xgb_n_estimators': 434, 'xgb_max_depth': 12, 'xgb_subsample': 0.993977362502418, 'xgb_colsample_bytree': 0.7311686459000545, 'xgb_reg_alpha': 0.004914745829751867, 'xgb_reg_lambda': 1.2917867076247607e-07, 'threshold': 0.6912089195623471}. Best is trial 13 with value: 0.6847980782452687.\n",
      "INFO:root:Starting trial 16 for F0.5 optimization\n",
      "INFO:root:Trial 16 completed with average F0.5 Score: 0.683461977389384\n",
      "[I 2024-10-02 14:07:23,643] Trial 16 finished with value: 0.683461977389384 and parameters: {'xgb_learning_rate': 0.06991435884883644, 'xgb_n_estimators': 353, 'xgb_max_depth': 10, 'xgb_subsample': 0.8747725657557075, 'xgb_colsample_bytree': 0.636885364387695, 'xgb_reg_alpha': 0.0012720215488521988, 'xgb_reg_lambda': 1.017767028498989e-05, 'threshold': 0.5259860999433761}. Best is trial 13 with value: 0.6847980782452687.\n",
      "INFO:root:Starting trial 17 for F0.5 optimization\n",
      "INFO:root:Trial 17 completed with average F0.5 Score: 0.6473624756369347\n",
      "[I 2024-10-02 14:07:35,934] Trial 17 finished with value: 0.6473624756369347 and parameters: {'xgb_learning_rate': 0.019031659343318068, 'xgb_n_estimators': 256, 'xgb_max_depth': 7, 'xgb_subsample': 0.9263592932094136, 'xgb_colsample_bytree': 0.737203545425472, 'xgb_reg_alpha': 0.019505894606613627, 'xgb_reg_lambda': 0.00021485109626423395, 'threshold': 0.3657882601369109}. Best is trial 13 with value: 0.6847980782452687.\n",
      "INFO:root:Starting trial 18 for F0.5 optimization\n",
      "INFO:root:Trial 18 completed with average F0.5 Score: 0.6350846465321344\n",
      "[I 2024-10-02 14:08:17,355] Trial 18 finished with value: 0.6350846465321344 and parameters: {'xgb_learning_rate': 0.005361754413952404, 'xgb_n_estimators': 455, 'xgb_max_depth': 11, 'xgb_subsample': 0.8279710323508951, 'xgb_colsample_bytree': 0.8083759384414602, 'xgb_reg_alpha': 0.5708927431761043, 'xgb_reg_lambda': 1.0467191128885468e-08, 'threshold': 0.7212159514902655}. Best is trial 13 with value: 0.6847980782452687.\n",
      "INFO:root:Starting trial 19 for F0.5 optimization\n",
      "INFO:root:Trial 19 completed with average F0.5 Score: 0.6836467356228482\n",
      "[I 2024-10-02 14:08:28,591] Trial 19 finished with value: 0.6836467356228482 and parameters: {'xgb_learning_rate': 0.03281361676046247, 'xgb_n_estimators': 354, 'xgb_max_depth': 10, 'xgb_subsample': 0.9464480270987892, 'xgb_colsample_bytree': 0.8456156715671481, 'xgb_reg_alpha': 0.0004232025525409645, 'xgb_reg_lambda': 2.5506192216136173e-07, 'threshold': 0.5007717801265785}. Best is trial 13 with value: 0.6847980782452687.\n",
      "INFO:root:Starting trial 20 for F0.5 optimization\n",
      "INFO:root:Trial 20 completed with average F0.5 Score: 0.3109950523877851\n",
      "[I 2024-10-02 14:08:51,464] Trial 20 finished with value: 0.3109950523877851 and parameters: {'xgb_learning_rate': 0.0015238757045142042, 'xgb_n_estimators': 385, 'xgb_max_depth': 8, 'xgb_subsample': 0.9966767947005449, 'xgb_colsample_bytree': 0.7281410484726347, 'xgb_reg_alpha': 0.011243488863528259, 'xgb_reg_lambda': 0.00011419486025631587, 'threshold': 0.6645185205862512}. Best is trial 13 with value: 0.6847980782452687.\n",
      "INFO:root:Starting trial 21 for F0.5 optimization\n",
      "INFO:root:Trial 21 completed with average F0.5 Score: 0.6846716176155309\n",
      "[I 2024-10-02 14:09:02,792] Trial 21 finished with value: 0.6846716176155309 and parameters: {'xgb_learning_rate': 0.03264563323488317, 'xgb_n_estimators': 371, 'xgb_max_depth': 10, 'xgb_subsample': 0.9374716108607292, 'xgb_colsample_bytree': 0.841945168258286, 'xgb_reg_alpha': 0.00033704462550387525, 'xgb_reg_lambda': 1.2137184888807772e-07, 'threshold': 0.49996947284955917}. Best is trial 13 with value: 0.6847980782452687.\n",
      "INFO:root:Starting trial 22 for F0.5 optimization\n",
      "INFO:root:Trial 22 completed with average F0.5 Score: 0.6867973471960054\n",
      "[I 2024-10-02 14:09:26,318] Trial 22 finished with value: 0.6867973471960054 and parameters: {'xgb_learning_rate': 0.013129234183468426, 'xgb_n_estimators': 282, 'xgb_max_depth': 11, 'xgb_subsample': 0.8928023466804488, 'xgb_colsample_bytree': 0.7699735631256108, 'xgb_reg_alpha': 0.0010506642156886817, 'xgb_reg_lambda': 7.984224587964035e-08, 'threshold': 0.5586537722256705}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 23 for F0.5 optimization\n",
      "INFO:root:Trial 23 completed with average F0.5 Score: 0.6802630122755373\n",
      "[I 2024-10-02 14:09:47,715] Trial 23 finished with value: 0.6802630122755373 and parameters: {'xgb_learning_rate': 0.015380232608337216, 'xgb_n_estimators': 291, 'xgb_max_depth': 11, 'xgb_subsample': 0.9094019138322877, 'xgb_colsample_bytree': 0.7687810282728023, 'xgb_reg_alpha': 2.3528600588090774e-05, 'xgb_reg_lambda': 3.040811143088901e-06, 'threshold': 0.4613761171146458}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 24 for F0.5 optimization\n",
      "INFO:root:Trial 24 completed with average F0.5 Score: 0.6834288194450268\n",
      "[I 2024-10-02 14:09:56,729] Trial 24 finished with value: 0.6834288194450268 and parameters: {'xgb_learning_rate': 0.04504368947291884, 'xgb_n_estimators': 219, 'xgb_max_depth': 10, 'xgb_subsample': 0.9611372533994876, 'xgb_colsample_bytree': 0.8453540553660479, 'xgb_reg_alpha': 0.002232531918276801, 'xgb_reg_lambda': 3.579574047292105e-07, 'threshold': 0.5799140567592441}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 25 for F0.5 optimization\n",
      "INFO:root:Trial 25 completed with average F0.5 Score: 0.6775582774674888\n",
      "[I 2024-10-02 14:10:10,461] Trial 25 finished with value: 0.6775582774674888 and parameters: {'xgb_learning_rate': 0.027834001815589402, 'xgb_n_estimators': 282, 'xgb_max_depth': 11, 'xgb_subsample': 0.9003561010236515, 'xgb_colsample_bytree': 0.7565149377058352, 'xgb_reg_alpha': 0.0003819643864765699, 'xgb_reg_lambda': 5.028706217931229e-08, 'threshold': 0.6417429984470969}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 26 for F0.5 optimization\n",
      "INFO:root:Trial 26 completed with average F0.5 Score: 0.6839515574052804\n",
      "[I 2024-10-02 14:10:31,171] Trial 26 finished with value: 0.6839515574052804 and parameters: {'xgb_learning_rate': 0.01389693068815841, 'xgb_n_estimators': 362, 'xgb_max_depth': 9, 'xgb_subsample': 0.9586255054139903, 'xgb_colsample_bytree': 0.827692829424562, 'xgb_reg_alpha': 1.2409370454215692e-05, 'xgb_reg_lambda': 7.055446238626861e-07, 'threshold': 0.5540166850770633}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 27 for F0.5 optimization\n",
      "INFO:root:Trial 27 completed with average F0.5 Score: 0.6488257684694543\n",
      "[I 2024-10-02 14:10:49,944] Trial 27 finished with value: 0.6488257684694543 and parameters: {'xgb_learning_rate': 0.005623343291294375, 'xgb_n_estimators': 207, 'xgb_max_depth': 10, 'xgb_subsample': 0.8246320176204615, 'xgb_colsample_bytree': 0.7814945174803154, 'xgb_reg_alpha': 0.00022321082718722155, 'xgb_reg_lambda': 9.793690270785894e-08, 'threshold': 0.4234795679315506}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 28 for F0.5 optimization\n",
      "INFO:root:Trial 28 completed with average F0.5 Score: 0.643312768319109\n",
      "[I 2024-10-02 14:11:04,028] Trial 28 finished with value: 0.643312768319109 and parameters: {'xgb_learning_rate': 0.020156287936019954, 'xgb_n_estimators': 296, 'xgb_max_depth': 7, 'xgb_subsample': 0.8902484585882788, 'xgb_colsample_bytree': 0.8708711654556134, 'xgb_reg_alpha': 0.0009208984163001087, 'xgb_reg_lambda': 6.717400195457838e-06, 'threshold': 0.33500124297046974}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 29 for F0.5 optimization\n",
      "INFO:root:Trial 29 completed with average F0.5 Score: 0.6816126705062382\n",
      "[I 2024-10-02 14:11:12,564] Trial 29 finished with value: 0.6816126705062382 and parameters: {'xgb_learning_rate': 0.047817325300997894, 'xgb_n_estimators': 326, 'xgb_max_depth': 8, 'xgb_subsample': 0.9328201224099831, 'xgb_colsample_bytree': 0.809215751275453, 'xgb_reg_alpha': 0.00435901327762944, 'xgb_reg_lambda': 3.8463763560348156e-05, 'threshold': 0.48482130476418384}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 30 for F0.5 optimization\n",
      "INFO:root:Trial 30 completed with average F0.5 Score: 0.6798994142114863\n",
      "[I 2024-10-02 14:11:19,321] Trial 30 finished with value: 0.6798994142114863 and parameters: {'xgb_learning_rate': 0.09736347890111037, 'xgb_n_estimators': 374, 'xgb_max_depth': 11, 'xgb_subsample': 0.9718988923933665, 'xgb_colsample_bytree': 0.809143595448038, 'xgb_reg_alpha': 0.00010730914083931356, 'xgb_reg_lambda': 8.686410260769975e-07, 'threshold': 0.5222477485483368}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 31 for F0.5 optimization\n",
      "INFO:root:Trial 31 completed with average F0.5 Score: 0.6860919910758213\n",
      "[I 2024-10-02 14:11:47,138] Trial 31 finished with value: 0.6860919910758213 and parameters: {'xgb_learning_rate': 0.011332287066815326, 'xgb_n_estimators': 425, 'xgb_max_depth': 12, 'xgb_subsample': 0.8747462000188302, 'xgb_colsample_bytree': 0.7077632456036655, 'xgb_reg_alpha': 0.009509650631124673, 'xgb_reg_lambda': 4.3575213001537315e-08, 'threshold': 0.5372875614824848}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 32 for F0.5 optimization\n",
      "INFO:root:Trial 32 completed with average F0.5 Score: 0.6739480055615324\n",
      "[I 2024-10-02 14:11:59,123] Trial 32 finished with value: 0.6739480055615324 and parameters: {'xgb_learning_rate': 0.03757489954644, 'xgb_n_estimators': 459, 'xgb_max_depth': 12, 'xgb_subsample': 0.8982401317276684, 'xgb_colsample_bytree': 0.7516655649802576, 'xgb_reg_alpha': 0.0011414452082270134, 'xgb_reg_lambda': 2.184001200809957e-07, 'threshold': 0.447756499141529}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 33 for F0.5 optimization\n",
      "INFO:root:Trial 33 completed with average F0.5 Score: 0.6825548303546902\n",
      "[I 2024-10-02 14:12:26,854] Trial 33 finished with value: 0.6825548303546902 and parameters: {'xgb_learning_rate': 0.01092369914365781, 'xgb_n_estimators': 415, 'xgb_max_depth': 12, 'xgb_subsample': 0.9603595356003417, 'xgb_colsample_bytree': 0.712766312139561, 'xgb_reg_alpha': 0.005651004857425639, 'xgb_reg_lambda': 2.4095888212856233e-08, 'threshold': 0.6052314927968305}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 34 for F0.5 optimization\n",
      "INFO:root:Trial 34 completed with average F0.5 Score: 0.6850272390544192\n",
      "[I 2024-10-02 14:12:57,310] Trial 34 finished with value: 0.6850272390544192 and parameters: {'xgb_learning_rate': 0.0066445655097217265, 'xgb_n_estimators': 468, 'xgb_max_depth': 9, 'xgb_subsample': 0.9241889630578471, 'xgb_colsample_bytree': 0.7900666417910827, 'xgb_reg_alpha': 0.06600766291794073, 'xgb_reg_lambda': 9.19152952515812e-08, 'threshold': 0.5263339105606566}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 35 for F0.5 optimization\n",
      "INFO:root:Trial 35 completed with average F0.5 Score: 0.6837536142834563\n",
      "[I 2024-10-02 14:13:28,013] Trial 35 finished with value: 0.6837536142834563 and parameters: {'xgb_learning_rate': 0.00534652978510508, 'xgb_n_estimators': 466, 'xgb_max_depth': 9, 'xgb_subsample': 0.8428481399333485, 'xgb_colsample_bytree': 0.7785203849476058, 'xgb_reg_alpha': 0.08572570886457281, 'xgb_reg_lambda': 1.205507061812957e-06, 'threshold': 0.544584912096791}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 36 for F0.5 optimization\n",
      "INFO:root:Trial 36 completed with average F0.5 Score: 0.684895929266414\n",
      "[I 2024-10-02 14:14:07,589] Trial 36 finished with value: 0.684895929266414 and parameters: {'xgb_learning_rate': 0.0067565376636140205, 'xgb_n_estimators': 476, 'xgb_max_depth': 11, 'xgb_subsample': 0.8822385981859173, 'xgb_colsample_bytree': 0.7023824144182219, 'xgb_reg_alpha': 0.011047034945781216, 'xgb_reg_lambda': 2.6113815527608282e-08, 'threshold': 0.6068134049577318}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 37 for F0.5 optimization\n",
      "INFO:root:Trial 37 completed with average F0.5 Score: 0.6054014526923996\n",
      "[I 2024-10-02 14:14:28,866] Trial 37 finished with value: 0.6054014526923996 and parameters: {'xgb_learning_rate': 0.0063820591828447305, 'xgb_n_estimators': 478, 'xgb_max_depth': 5, 'xgb_subsample': 0.7974140386333372, 'xgb_colsample_bytree': 0.7022075264396792, 'xgb_reg_alpha': 0.07733239038323797, 'xgb_reg_lambda': 2.2381519397217593e-08, 'threshold': 0.6569082906882793}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 38 for F0.5 optimization\n",
      "INFO:root:Trial 38 completed with average F0.5 Score: 0.6834142305008706\n",
      "[I 2024-10-02 14:15:16,226] Trial 38 finished with value: 0.6834142305008706 and parameters: {'xgb_learning_rate': 0.004561630731975122, 'xgb_n_estimators': 440, 'xgb_max_depth': 12, 'xgb_subsample': 0.8796785952516573, 'xgb_colsample_bytree': 0.6612673022278802, 'xgb_reg_alpha': 0.1869587299193204, 'xgb_reg_lambda': 7.007821076301836e-08, 'threshold': 0.6143029115824802}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 39 for F0.5 optimization\n",
      "INFO:root:Trial 39 completed with average F0.5 Score: 0.64253634475756\n",
      "[I 2024-10-02 14:15:21,487] Trial 39 finished with value: 0.64253634475756 and parameters: {'xgb_learning_rate': 0.007787571497754962, 'xgb_n_estimators': 79, 'xgb_max_depth': 8, 'xgb_subsample': 0.8612031230269858, 'xgb_colsample_bytree': 0.7449278553950546, 'xgb_reg_alpha': 0.012768658800595434, 'xgb_reg_lambda': 1.1385235335141286e-08, 'threshold': 0.45268397479252936}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 40 for F0.5 optimization\n",
      "INFO:root:Trial 40 completed with average F0.5 Score: 0.4808077467089432\n",
      "[I 2024-10-02 14:15:30,169] Trial 40 finished with value: 0.4808077467089432 and parameters: {'xgb_learning_rate': 0.003596931770171395, 'xgb_n_estimators': 115, 'xgb_max_depth': 9, 'xgb_subsample': 0.7927807597745864, 'xgb_colsample_bytree': 0.7095280793235353, 'xgb_reg_alpha': 0.030200112781441718, 'xgb_reg_lambda': 4.047520951260391e-07, 'threshold': 0.6039306845417236}. Best is trial 22 with value: 0.6867973471960054.\n",
      "INFO:root:Starting trial 41 for F0.5 optimization\n",
      "INFO:root:Trial 41 completed with average F0.5 Score: 0.6877094220501249\n",
      "[I 2024-10-02 14:15:55,478] Trial 41 finished with value: 0.6877094220501249 and parameters: {'xgb_learning_rate': 0.011482428344823785, 'xgb_n_estimators': 500, 'xgb_max_depth': 11, 'xgb_subsample': 0.9203132603198677, 'xgb_colsample_bytree': 0.7577254055330669, 'xgb_reg_alpha': 0.010546537769960493, 'xgb_reg_lambda': 3.7102345649013086e-08, 'threshold': 0.5647871931942834}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 42 for F0.5 optimization\n",
      "INFO:root:Trial 42 completed with average F0.5 Score: 0.6871495766402937\n",
      "[I 2024-10-02 14:16:23,043] Trial 42 finished with value: 0.6871495766402937 and parameters: {'xgb_learning_rate': 0.01025976226391536, 'xgb_n_estimators': 492, 'xgb_max_depth': 11, 'xgb_subsample': 0.9196186720557544, 'xgb_colsample_bytree': 0.7518003144152038, 'xgb_reg_alpha': 0.008231515612258109, 'xgb_reg_lambda': 3.0933265779269734e-08, 'threshold': 0.5333659962198033}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 43 for F0.5 optimization\n",
      "INFO:root:Trial 43 completed with average F0.5 Score: 0.6854100246569698\n",
      "[I 2024-10-02 14:16:52,610] Trial 43 finished with value: 0.6854100246569698 and parameters: {'xgb_learning_rate': 0.010328042357506116, 'xgb_n_estimators': 499, 'xgb_max_depth': 12, 'xgb_subsample': 0.9203533474294084, 'xgb_colsample_bytree': 0.7473040854187106, 'xgb_reg_alpha': 0.039600582887328074, 'xgb_reg_lambda': 1.4239586513301838e-07, 'threshold': 0.5385806734376636}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 44 for F0.5 optimization\n",
      "INFO:root:Trial 44 completed with average F0.5 Score: 0.6869841058256074\n",
      "[I 2024-10-02 14:17:20,829] Trial 44 finished with value: 0.6869841058256074 and parameters: {'xgb_learning_rate': 0.010706824657353353, 'xgb_n_estimators': 500, 'xgb_max_depth': 12, 'xgb_subsample': 0.9133529954906869, 'xgb_colsample_bytree': 0.759788925073531, 'xgb_reg_alpha': 0.030970059018030287, 'xgb_reg_lambda': 4.520680613452411e-08, 'threshold': 0.5717789786248259}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 45 for F0.5 optimization\n",
      "INFO:root:Trial 45 completed with average F0.5 Score: 0.670152506395897\n",
      "[I 2024-10-02 14:17:27,618] Trial 45 finished with value: 0.670152506395897 and parameters: {'xgb_learning_rate': 0.011878100474977019, 'xgb_n_estimators': 51, 'xgb_max_depth': 12, 'xgb_subsample': 0.9028613706852642, 'xgb_colsample_bytree': 0.7308026319753008, 'xgb_reg_alpha': 0.007279449635345023, 'xgb_reg_lambda': 2.5891541925844073e-08, 'threshold': 0.5711383448445837}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 46 for F0.5 optimization\n",
      "INFO:root:Trial 46 completed with average F0.5 Score: 0.6835125832428424\n",
      "[I 2024-10-02 14:17:43,039] Trial 46 finished with value: 0.6835125832428424 and parameters: {'xgb_learning_rate': 0.022287664531065635, 'xgb_n_estimators': 450, 'xgb_max_depth': 11, 'xgb_subsample': 0.8570167874780851, 'xgb_colsample_bytree': 0.7610106521541058, 'xgb_reg_alpha': 0.022010463725491536, 'xgb_reg_lambda': 6.127422629298635e-08, 'threshold': 0.4864202842079841}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 47 for F0.5 optimization\n",
      "INFO:root:Trial 47 completed with average F0.5 Score: 0.6542487624803411\n",
      "[I 2024-10-02 14:18:19,002] Trial 47 finished with value: 0.6542487624803411 and parameters: {'xgb_learning_rate': 0.008559297913857263, 'xgb_n_estimators': 414, 'xgb_max_depth': 12, 'xgb_subsample': 0.8892560754280933, 'xgb_colsample_bytree': 0.6729572675681249, 'xgb_reg_alpha': 0.004174018901353498, 'xgb_reg_lambda': 1.0122705353301457e-08, 'threshold': 0.3938067502164766}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 48 for F0.5 optimization\n",
      "INFO:root:Trial 48 completed with average F0.5 Score: 0.651660617619084\n",
      "[I 2024-10-02 14:18:36,584] Trial 48 finished with value: 0.651660617619084 and parameters: {'xgb_learning_rate': 0.014682647297195059, 'xgb_n_estimators': 487, 'xgb_max_depth': 3, 'xgb_subsample': 0.933865490075932, 'xgb_colsample_bytree': 0.7922264198728353, 'xgb_reg_alpha': 0.009703089085041805, 'xgb_reg_lambda': 3.97476525969106e-07, 'threshold': 0.5810909694172649}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 49 for F0.5 optimization\n",
      "INFO:root:Trial 49 completed with average F0.5 Score: 0.6784481221417688\n",
      "[I 2024-10-02 14:18:51,093] Trial 49 finished with value: 0.6784481221417688 and parameters: {'xgb_learning_rate': 0.0234451576114882, 'xgb_n_estimators': 437, 'xgb_max_depth': 10, 'xgb_subsample': 0.9149632973788596, 'xgb_colsample_bytree': 0.7177443830997174, 'xgb_reg_alpha': 0.1877378442491723, 'xgb_reg_lambda': 5.016085003520854e-08, 'threshold': 0.6387617935103954}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 50 for F0.5 optimization\n",
      "INFO:root:Trial 50 completed with average F0.5 Score: 0.6591344452775733\n",
      "[I 2024-10-02 14:19:22,897] Trial 50 finished with value: 0.6591344452775733 and parameters: {'xgb_learning_rate': 0.008756246309091647, 'xgb_n_estimators': 500, 'xgb_max_depth': 11, 'xgb_subsample': 0.9791102780812772, 'xgb_colsample_bytree': 0.7595476186482747, 'xgb_reg_alpha': 0.002023596723512698, 'xgb_reg_lambda': 2.2586573306310036e-07, 'threshold': 0.6924135053814636}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 51 for F0.5 optimization\n",
      "INFO:root:Trial 51 completed with average F0.5 Score: 0.6850069037877675\n",
      "[I 2024-10-02 14:19:49,297] Trial 51 finished with value: 0.6850069037877675 and parameters: {'xgb_learning_rate': 0.011700362363630997, 'xgb_n_estimators': 499, 'xgb_max_depth': 12, 'xgb_subsample': 0.9462162221234629, 'xgb_colsample_bytree': 0.742889508093981, 'xgb_reg_alpha': 0.03870725973209552, 'xgb_reg_lambda': 1.1438985150807016e-07, 'threshold': 0.5385309487061157}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 52 for F0.5 optimization\n",
      "INFO:root:Trial 52 completed with average F0.5 Score: 0.6861560795841245\n",
      "[I 2024-10-02 14:20:09,112] Trial 52 finished with value: 0.6861560795841245 and parameters: {'xgb_learning_rate': 0.016740007089858382, 'xgb_n_estimators': 479, 'xgb_max_depth': 12, 'xgb_subsample': 0.918969373381457, 'xgb_colsample_bytree': 0.6903059250165998, 'xgb_reg_alpha': 0.022422943027805873, 'xgb_reg_lambda': 3.2783395329213516e-08, 'threshold': 0.5598504278047097}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 53 for F0.5 optimization\n",
      "INFO:root:Trial 53 completed with average F0.5 Score: 0.6862220476501196\n",
      "[I 2024-10-02 14:20:30,360] Trial 53 finished with value: 0.6862220476501196 and parameters: {'xgb_learning_rate': 0.015621709461737215, 'xgb_n_estimators': 418, 'xgb_max_depth': 12, 'xgb_subsample': 0.8680364219191398, 'xgb_colsample_bytree': 0.686311084923807, 'xgb_reg_alpha': 0.020033387054220822, 'xgb_reg_lambda': 3.572621848750232e-08, 'threshold': 0.5738577945099234}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 54 for F0.5 optimization\n",
      "INFO:root:Trial 54 completed with average F0.5 Score: 0.6868007287907568\n",
      "[I 2024-10-02 14:20:48,482] Trial 54 finished with value: 0.6868007287907568 and parameters: {'xgb_learning_rate': 0.017639582191188143, 'xgb_n_estimators': 481, 'xgb_max_depth': 11, 'xgb_subsample': 0.9064886050359586, 'xgb_colsample_bytree': 0.6529960452760408, 'xgb_reg_alpha': 0.01933855898304535, 'xgb_reg_lambda': 1.9810395044244475e-08, 'threshold': 0.5835597870303229}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 55 for F0.5 optimization\n",
      "INFO:root:Trial 55 completed with average F0.5 Score: 0.6854184781985432\n",
      "[I 2024-10-02 14:21:01,821] Trial 55 finished with value: 0.6854184781985432 and parameters: {'xgb_learning_rate': 0.02737726832447921, 'xgb_n_estimators': 456, 'xgb_max_depth': 11, 'xgb_subsample': 0.9750621860539765, 'xgb_colsample_bytree': 0.6525225153173555, 'xgb_reg_alpha': 0.0040717892839383305, 'xgb_reg_lambda': 1.7179828402378922e-08, 'threshold': 0.5791766746162837}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 56 for F0.5 optimization\n",
      "INFO:root:Trial 56 completed with average F0.5 Score: 0.685546994866802\n",
      "[I 2024-10-02 14:21:13,355] Trial 56 finished with value: 0.685546994866802 and parameters: {'xgb_learning_rate': 0.01957721095242974, 'xgb_n_estimators': 143, 'xgb_max_depth': 10, 'xgb_subsample': 0.8942875432573214, 'xgb_colsample_bytree': 0.6147699824341615, 'xgb_reg_alpha': 0.015310872568827365, 'xgb_reg_lambda': 1.523814542205236e-08, 'threshold': 0.5121595666283728}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 57 for F0.5 optimization\n",
      "INFO:root:Trial 57 completed with average F0.5 Score: 0.6823031530614364\n",
      "[I 2024-10-02 14:21:31,439] Trial 57 finished with value: 0.6823031530614364 and parameters: {'xgb_learning_rate': 0.015668938209868106, 'xgb_n_estimators': 185, 'xgb_max_depth': 11, 'xgb_subsample': 0.9417862631521433, 'xgb_colsample_bytree': 0.5786116716580305, 'xgb_reg_alpha': 0.0008011834213477935, 'xgb_reg_lambda': 1.9785186615322911e-07, 'threshold': 0.6226755085284319}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 58 for F0.5 optimization\n",
      "INFO:root:Trial 58 completed with average F0.5 Score: 0.646958308179718\n",
      "[I 2024-10-02 14:21:49,469] Trial 58 finished with value: 0.646958308179718 and parameters: {'xgb_learning_rate': 0.009019984904675584, 'xgb_n_estimators': 448, 'xgb_max_depth': 4, 'xgb_subsample': 0.8454792297443644, 'xgb_colsample_bytree': 0.6862505667120926, 'xgb_reg_alpha': 0.002460996174419738, 'xgb_reg_lambda': 4.4565991930097006e-08, 'threshold': 0.5937533153636229}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 59 for F0.5 optimization\n",
      "INFO:root:Trial 59 completed with average F0.5 Score: 0.6827715872695992\n",
      "[I 2024-10-02 14:22:11,939] Trial 59 finished with value: 0.6827715872695992 and parameters: {'xgb_learning_rate': 0.013413564272924427, 'xgb_n_estimators': 265, 'xgb_max_depth': 11, 'xgb_subsample': 0.9094345800755329, 'xgb_colsample_bytree': 0.7195172599060988, 'xgb_reg_alpha': 0.043373664048751225, 'xgb_reg_lambda': 6.793063855298612e-08, 'threshold': 0.4807063902159894}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 60 for F0.5 optimization\n",
      "INFO:root:Trial 60 completed with average F0.5 Score: 0.6850657895249179\n",
      "[I 2024-10-02 14:22:29,380] Trial 60 finished with value: 0.6850657895249179 and parameters: {'xgb_learning_rate': 0.0175767951981087, 'xgb_n_estimators': 340, 'xgb_max_depth': 10, 'xgb_subsample': 0.8751875246372298, 'xgb_colsample_bytree': 0.7296897635963927, 'xgb_reg_alpha': 0.14986574086518253, 'xgb_reg_lambda': 5.801990337462092e-07, 'threshold': 0.5064969650651409}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 61 for F0.5 optimization\n",
      "INFO:root:Trial 61 completed with average F0.5 Score: 0.6868191406294794\n",
      "[I 2024-10-02 14:22:49,884] Trial 61 finished with value: 0.6868191406294794 and parameters: {'xgb_learning_rate': 0.01643858813765658, 'xgb_n_estimators': 481, 'xgb_max_depth': 12, 'xgb_subsample': 0.919863112902943, 'xgb_colsample_bytree': 0.6852582535018531, 'xgb_reg_alpha': 0.021014485501052768, 'xgb_reg_lambda': 4.278615697274042e-08, 'threshold': 0.5685017254191319}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 62 for F0.5 optimization\n",
      "INFO:root:Trial 62 completed with average F0.5 Score: 0.6857109514732203\n",
      "[I 2024-10-02 14:23:05,981] Trial 62 finished with value: 0.6857109514732203 and parameters: {'xgb_learning_rate': 0.023075933755939228, 'xgb_n_estimators': 481, 'xgb_max_depth': 12, 'xgb_subsample': 0.9483662306840551, 'xgb_colsample_bytree': 0.6846520976933582, 'xgb_reg_alpha': 0.014019470368564798, 'xgb_reg_lambda': 1.987025575595092e-08, 'threshold': 0.5621518724414228}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 63 for F0.5 optimization\n",
      "INFO:root:Trial 63 completed with average F0.5 Score: 0.6797862806746544\n",
      "[I 2024-10-02 14:23:31,004] Trial 63 finished with value: 0.6797862806746544 and parameters: {'xgb_learning_rate': 0.012078414300327437, 'xgb_n_estimators': 463, 'xgb_max_depth': 11, 'xgb_subsample': 0.9296044403344041, 'xgb_colsample_bytree': 0.6633446218255179, 'xgb_reg_alpha': 0.0060202435177705745, 'xgb_reg_lambda': 1.5360360283036984e-07, 'threshold': 0.6310934939931226}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 64 for F0.5 optimization\n",
      "INFO:root:Trial 64 completed with average F0.5 Score: 0.6864439225442986\n",
      "[I 2024-10-02 14:24:04,801] Trial 64 finished with value: 0.6864439225442986 and parameters: {'xgb_learning_rate': 0.008616038205665852, 'xgb_n_estimators': 422, 'xgb_max_depth': 12, 'xgb_subsample': 0.9042963608870145, 'xgb_colsample_bytree': 0.7696453673721108, 'xgb_reg_alpha': 0.024415214397039996, 'xgb_reg_lambda': 1.0240141331097216e-08, 'threshold': 0.5951148010915209}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 65 for F0.5 optimization\n",
      "INFO:root:Trial 65 completed with average F0.5 Score: 0.6865520654477126\n",
      "[I 2024-10-02 14:24:36,738] Trial 65 finished with value: 0.6865520654477126 and parameters: {'xgb_learning_rate': 0.00888545301622292, 'xgb_n_estimators': 486, 'xgb_max_depth': 11, 'xgb_subsample': 0.9062766659457834, 'xgb_colsample_bytree': 0.7706720534643877, 'xgb_reg_alpha': 0.04909274318526647, 'xgb_reg_lambda': 1.1689858309009183e-08, 'threshold': 0.593136690615588}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 66 for F0.5 optimization\n",
      "INFO:root:Trial 66 completed with average F0.5 Score: 0.6374618448858381\n",
      "[I 2024-10-02 14:25:09,495] Trial 66 finished with value: 0.6374618448858381 and parameters: {'xgb_learning_rate': 0.004423065772249818, 'xgb_n_estimators': 394, 'xgb_max_depth': 10, 'xgb_subsample': 0.9802944870822407, 'xgb_colsample_bytree': 0.7944139791769257, 'xgb_reg_alpha': 0.048097063572122414, 'xgb_reg_lambda': 8.246380364713622e-08, 'threshold': 0.6775898166810801}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 67 for F0.5 optimization\n",
      "INFO:root:Trial 67 completed with average F0.5 Score: 0.6847339353016823\n",
      "[I 2024-10-02 14:25:26,068] Trial 67 finished with value: 0.6847339353016823 and parameters: {'xgb_learning_rate': 0.01932525613875302, 'xgb_n_estimators': 481, 'xgb_max_depth': 11, 'xgb_subsample': 0.9594660070233065, 'xgb_colsample_bytree': 0.7634963104712357, 'xgb_reg_alpha': 0.1115093874355172, 'xgb_reg_lambda': 2.0142271145452024e-08, 'threshold': 0.5094091990842985}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 68 for F0.5 optimization\n",
      "INFO:root:Trial 68 completed with average F0.5 Score: 0.6791139628513507\n",
      "[I 2024-10-02 14:25:38,106] Trial 68 finished with value: 0.6791139628513507 and parameters: {'xgb_learning_rate': 0.0302551609888474, 'xgb_n_estimators': 469, 'xgb_max_depth': 10, 'xgb_subsample': 0.8904768928409137, 'xgb_colsample_bytree': 0.7348514988089648, 'xgb_reg_alpha': 0.30293426958172015, 'xgb_reg_lambda': 3.6159622896851964e-08, 'threshold': 0.6424311778751659}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 69 for F0.5 optimization\n",
      "INFO:root:Trial 69 completed with average F0.5 Score: 0.6843572844074594\n",
      "[I 2024-10-02 14:26:05,517] Trial 69 finished with value: 0.6843572844074594 and parameters: {'xgb_learning_rate': 0.010310851465216467, 'xgb_n_estimators': 489, 'xgb_max_depth': 11, 'xgb_subsample': 0.9328919347379283, 'xgb_colsample_bytree': 0.8210887393942732, 'xgb_reg_alpha': 0.07171792882000479, 'xgb_reg_lambda': 2.650765975297699e-07, 'threshold': 0.5518712507633085}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 70 for F0.5 optimization\n",
      "INFO:root:Trial 70 completed with average F0.5 Score: 0.6814124978692899\n",
      "[I 2024-10-02 14:26:28,479] Trial 70 finished with value: 0.6814124978692899 and parameters: {'xgb_learning_rate': 0.012753948062725699, 'xgb_n_estimators': 448, 'xgb_max_depth': 11, 'xgb_subsample': 0.9133156032116156, 'xgb_colsample_bytree': 0.7755265826257, 'xgb_reg_alpha': 0.007138815069990374, 'xgb_reg_lambda': 9.128483159594261e-08, 'threshold': 0.47146843739681865}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 71 for F0.5 optimization\n",
      "INFO:root:Trial 71 completed with average F0.5 Score: 0.6866283500304629\n",
      "[I 2024-10-02 14:27:08,122] Trial 71 finished with value: 0.6866283500304629 and parameters: {'xgb_learning_rate': 0.007122445904519743, 'xgb_n_estimators': 490, 'xgb_max_depth': 12, 'xgb_subsample': 0.9042460620532476, 'xgb_colsample_bytree': 0.7729803026717187, 'xgb_reg_alpha': 0.030609443236171003, 'xgb_reg_lambda': 1.515749923001193e-08, 'threshold': 0.5946353602832847}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 72 for F0.5 optimization\n",
      "INFO:root:Trial 72 completed with average F0.5 Score: 0.6849160346916944\n",
      "[I 2024-10-02 14:27:44,673] Trial 72 finished with value: 0.6849160346916944 and parameters: {'xgb_learning_rate': 0.008063663935387145, 'xgb_n_estimators': 489, 'xgb_max_depth': 12, 'xgb_subsample': 0.899857327662684, 'xgb_colsample_bytree': 0.7571044500147197, 'xgb_reg_alpha': 0.05689955033511763, 'xgb_reg_lambda': 1.6988997054234133e-08, 'threshold': 0.6144738687521254}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 73 for F0.5 optimization\n",
      "INFO:root:Trial 73 completed with average F0.5 Score: 0.6871783635131075\n",
      "[I 2024-10-02 14:28:05,635] Trial 73 finished with value: 0.6871783635131075 and parameters: {'xgb_learning_rate': 0.014336420959779207, 'xgb_n_estimators': 309, 'xgb_max_depth': 11, 'xgb_subsample': 0.9238536744377932, 'xgb_colsample_bytree': 0.7877804847539792, 'xgb_reg_alpha': 0.03321821071006294, 'xgb_reg_lambda': 3.6648430880429004e-08, 'threshold': 0.5297758851633658}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 74 for F0.5 optimization\n",
      "INFO:root:Trial 74 completed with average F0.5 Score: 0.68627719261099\n",
      "[I 2024-10-02 14:28:27,346] Trial 74 finished with value: 0.68627719261099 and parameters: {'xgb_learning_rate': 0.013804965775381817, 'xgb_n_estimators': 307, 'xgb_max_depth': 11, 'xgb_subsample': 0.9521334384903912, 'xgb_colsample_bytree': 0.7854797650080116, 'xgb_reg_alpha': 0.008233170045171604, 'xgb_reg_lambda': 4.359231755295235e-08, 'threshold': 0.5336098257214033}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 75 for F0.5 optimization\n",
      "INFO:root:Trial 75 completed with average F0.5 Score: 0.685200259780369\n",
      "[I 2024-10-02 14:29:01,578] Trial 75 finished with value: 0.685200259780369 and parameters: {'xgb_learning_rate': 0.006941963316600617, 'xgb_n_estimators': 312, 'xgb_max_depth': 12, 'xgb_subsample': 0.9261781394973528, 'xgb_colsample_bytree': 0.7954014117389022, 'xgb_reg_alpha': 0.028654415489609657, 'xgb_reg_lambda': 1.527557299673999e-07, 'threshold': 0.5191666711550043}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 76 for F0.5 optimization\n",
      "INFO:root:Trial 76 completed with average F0.5 Score: 0.6831319077013359\n",
      "[I 2024-10-02 14:29:16,460] Trial 76 finished with value: 0.6831319077013359 and parameters: {'xgb_learning_rate': 0.02512119962661728, 'xgb_n_estimators': 220, 'xgb_max_depth': 12, 'xgb_subsample': 0.8807204142218538, 'xgb_colsample_bytree': 0.7418544439952461, 'xgb_reg_alpha': 0.01471885401684355, 'xgb_reg_lambda': 6.903340052218881e-08, 'threshold': 0.54356249241043}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 77 for F0.5 optimization\n",
      "INFO:root:Trial 77 completed with average F0.5 Score: 0.6837085856788934\n",
      "[I 2024-10-02 14:29:35,092] Trial 77 finished with value: 0.6837085856788934 and parameters: {'xgb_learning_rate': 0.01716552940850788, 'xgb_n_estimators': 247, 'xgb_max_depth': 11, 'xgb_subsample': 0.941827514760791, 'xgb_colsample_bytree': 0.722173260863294, 'xgb_reg_alpha': 0.0033461782133030597, 'xgb_reg_lambda': 3.553969904276403e-08, 'threshold': 0.4924028185570242}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 78 for F0.5 optimization\n",
      "INFO:root:Trial 78 completed with average F0.5 Score: 0.683596450063797\n",
      "[I 2024-10-02 14:29:56,859] Trial 78 finished with value: 0.683596450063797 and parameters: {'xgb_learning_rate': 0.020384076162368796, 'xgb_n_estimators': 464, 'xgb_max_depth': 6, 'xgb_subsample': 0.9599451624947352, 'xgb_colsample_bytree': 0.8003399395524553, 'xgb_reg_alpha': 0.0018544761815319996, 'xgb_reg_lambda': 2.3874932828176166e-08, 'threshold': 0.5830548879789407}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 79 for F0.5 optimization\n",
      "INFO:root:Trial 79 completed with average F0.5 Score: 0.6857217929445742\n",
      "[I 2024-10-02 14:30:18,554] Trial 79 finished with value: 0.6857217929445742 and parameters: {'xgb_learning_rate': 0.010067558626911412, 'xgb_n_estimators': 272, 'xgb_max_depth': 10, 'xgb_subsample': 0.9215444132777496, 'xgb_colsample_bytree': 0.8126315802108036, 'xgb_reg_alpha': 0.11092187156345847, 'xgb_reg_lambda': 2.77745447757543e-07, 'threshold': 0.5637912664563092}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 80 for F0.5 optimization\n",
      "INFO:root:Trial 80 completed with average F0.5 Score: 0.669676963967716\n",
      "[I 2024-10-02 14:30:30,312] Trial 80 finished with value: 0.669676963967716 and parameters: {'xgb_learning_rate': 0.03662022733045234, 'xgb_n_estimators': 291, 'xgb_max_depth': 12, 'xgb_subsample': 0.998468820681347, 'xgb_colsample_bytree': 0.7487151952778828, 'xgb_reg_alpha': 0.005066239076229156, 'xgb_reg_lambda': 1.4809907591613891e-07, 'threshold': 0.44019734990922804}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 81 for F0.5 optimization\n",
      "INFO:root:Trial 81 completed with average F0.5 Score: 0.6855809031081284\n",
      "[I 2024-10-02 14:30:59,459] Trial 81 finished with value: 0.6855809031081284 and parameters: {'xgb_learning_rate': 0.009845282126748171, 'xgb_n_estimators': 475, 'xgb_max_depth': 11, 'xgb_subsample': 0.9081512560360532, 'xgb_colsample_bytree': 0.7744912034069809, 'xgb_reg_alpha': 0.04686929547242149, 'xgb_reg_lambda': 1.3731982433114116e-08, 'threshold': 0.5922504186670452}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 82 for F0.5 optimization\n",
      "INFO:root:Trial 82 completed with average F0.5 Score: 0.6844687774205547\n",
      "[I 2024-10-02 14:31:37,594] Trial 82 finished with value: 0.6844687774205547 and parameters: {'xgb_learning_rate': 0.007241996678326917, 'xgb_n_estimators': 500, 'xgb_max_depth': 11, 'xgb_subsample': 0.888838183672912, 'xgb_colsample_bytree': 0.7837854925457669, 'xgb_reg_alpha': 0.028833420064278553, 'xgb_reg_lambda': 2.6739471180439432e-08, 'threshold': 0.618088036567072}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 83 for F0.5 optimization\n",
      "INFO:root:Trial 83 completed with average F0.5 Score: 0.6850701101078585\n",
      "[I 2024-10-02 14:32:00,305] Trial 83 finished with value: 0.6850701101078585 and parameters: {'xgb_learning_rate': 0.012950275606471414, 'xgb_n_estimators': 437, 'xgb_max_depth': 11, 'xgb_subsample': 0.9357403919461922, 'xgb_colsample_bytree': 0.7654702538239759, 'xgb_reg_alpha': 0.015607624902174155, 'xgb_reg_lambda': 1.042948274286209e-08, 'threshold': 0.5177171512777183}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 84 for F0.5 optimization\n",
      "INFO:root:Trial 84 completed with average F0.5 Score: 0.6865064270198695\n",
      "[I 2024-10-02 14:32:21,914] Trial 84 finished with value: 0.6865064270198695 and parameters: {'xgb_learning_rate': 0.014910945256273159, 'xgb_n_estimators': 488, 'xgb_max_depth': 12, 'xgb_subsample': 0.871837593530327, 'xgb_colsample_bytree': 0.7523125878740685, 'xgb_reg_alpha': 0.06681714417730075, 'xgb_reg_lambda': 5.597610611441107e-08, 'threshold': 0.5585851539223924}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 85 for F0.5 optimization\n",
      "INFO:root:Trial 85 completed with average F0.5 Score: 0.6662185758088202\n",
      "[I 2024-10-02 14:32:43,609] Trial 85 finished with value: 0.6662185758088202 and parameters: {'xgb_learning_rate': 0.010307238358207838, 'xgb_n_estimators': 469, 'xgb_max_depth': 7, 'xgb_subsample': 0.9001075327788298, 'xgb_colsample_bytree': 0.7782060549734334, 'xgb_reg_alpha': 0.010968886759627778, 'xgb_reg_lambda': 1.586117262222441e-08, 'threshold': 0.647222177261015}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 86 for F0.5 optimization\n",
      "INFO:root:Trial 86 completed with average F0.5 Score: 0.6845658994107842\n",
      "[I 2024-10-02 14:33:18,964] Trial 86 finished with value: 0.6845658994107842 and parameters: {'xgb_learning_rate': 0.006332193266035706, 'xgb_n_estimators': 459, 'xgb_max_depth': 10, 'xgb_subsample': 0.9165960481353964, 'xgb_colsample_bytree': 0.7319558230135741, 'xgb_reg_alpha': 0.02977204012142738, 'xgb_reg_lambda': 9.238101042547976e-08, 'threshold': 0.5955910552754863}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 87 for F0.5 optimization\n",
      "INFO:root:Trial 87 completed with average F0.5 Score: 0.6862792930683386\n",
      "[I 2024-10-02 14:33:56,248] Trial 87 finished with value: 0.6862792930683386 and parameters: {'xgb_learning_rate': 0.007945441959346822, 'xgb_n_estimators': 445, 'xgb_max_depth': 12, 'xgb_subsample': 0.9256124349294722, 'xgb_colsample_bytree': 0.8038717630336749, 'xgb_reg_alpha': 0.0032201663445281343, 'xgb_reg_lambda': 3.3091923026131815e-08, 'threshold': 0.5326408123890971}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 88 for F0.5 optimization\n",
      "INFO:root:Trial 88 completed with average F0.5 Score: 0.6800681907913464\n",
      "[I 2024-10-02 14:34:20,082] Trial 88 finished with value: 0.6800681907913464 and parameters: {'xgb_learning_rate': 0.012041157258600634, 'xgb_n_estimators': 492, 'xgb_max_depth': 11, 'xgb_subsample': 0.9697069997719852, 'xgb_colsample_bytree': 0.8290117734500296, 'xgb_reg_alpha': 0.007240528689813581, 'xgb_reg_lambda': 1.7686350368785826e-08, 'threshold': 0.4661018368387744}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 89 for F0.5 optimization\n",
      "INFO:root:Trial 89 completed with average F0.5 Score: 0.676492768096854\n",
      "[I 2024-10-02 14:34:38,879] Trial 89 finished with value: 0.676492768096854 and parameters: {'xgb_learning_rate': 0.01804328457432557, 'xgb_n_estimators': 334, 'xgb_max_depth': 12, 'xgb_subsample': 0.8603737512524411, 'xgb_colsample_bytree': 0.7070494681191369, 'xgb_reg_alpha': 0.01861577120188382, 'xgb_reg_lambda': 5.012664171643475e-08, 'threshold': 0.6608594145709483}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 90 for F0.5 optimization\n",
      "INFO:root:Trial 90 completed with average F0.5 Score: 0.6851280288127\n",
      "[I 2024-10-02 14:35:13,197] Trial 90 finished with value: 0.6851280288127 and parameters: {'xgb_learning_rate': 0.005558045087774125, 'xgb_n_estimators': 430, 'xgb_max_depth': 10, 'xgb_subsample': 0.9495109350844557, 'xgb_colsample_bytree': 0.7437326210377917, 'xgb_reg_alpha': 0.0446986046478585, 'xgb_reg_lambda': 9.958069054276234e-08, 'threshold': 0.5716151535668502}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 91 for F0.5 optimization\n",
      "INFO:root:Trial 91 completed with average F0.5 Score: 0.6859804346323755\n",
      "[I 2024-10-02 14:35:34,681] Trial 91 finished with value: 0.6859804346323755 and parameters: {'xgb_learning_rate': 0.015100400698547772, 'xgb_n_estimators': 489, 'xgb_max_depth': 12, 'xgb_subsample': 0.8831893166315191, 'xgb_colsample_bytree': 0.75820456568105, 'xgb_reg_alpha': 0.09310635191177447, 'xgb_reg_lambda': 5.969330849270927e-08, 'threshold': 0.5539726507431647}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 92 for F0.5 optimization\n",
      "INFO:root:Trial 92 completed with average F0.5 Score: 0.6852679862799493\n",
      "[I 2024-10-02 14:35:57,229] Trial 92 finished with value: 0.6852679862799493 and parameters: {'xgb_learning_rate': 0.014189296980863937, 'xgb_n_estimators': 479, 'xgb_max_depth': 12, 'xgb_subsample': 0.8962676357799674, 'xgb_colsample_bytree': 0.7527077948272979, 'xgb_reg_alpha': 0.058068113628837105, 'xgb_reg_lambda': 2.425340558486194e-08, 'threshold': 0.6073207143276652}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 93 for F0.5 optimization\n",
      "INFO:root:Trial 93 completed with average F0.5 Score: 0.6843956535403034\n",
      "[I 2024-10-02 14:36:12,818] Trial 93 finished with value: 0.6843956535403034 and parameters: {'xgb_learning_rate': 0.021846675550007716, 'xgb_n_estimators': 487, 'xgb_max_depth': 11, 'xgb_subsample': 0.8713184187088822, 'xgb_colsample_bytree': 0.7717750810070831, 'xgb_reg_alpha': 0.32246331013574514, 'xgb_reg_lambda': 5.61017000168132e-08, 'threshold': 0.5534193595991416}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 94 for F0.5 optimization\n",
      "INFO:root:Trial 94 completed with average F0.5 Score: 0.6842152917202067\n",
      "[I 2024-10-02 14:36:40,638] Trial 94 finished with value: 0.6842152917202067 and parameters: {'xgb_learning_rate': 0.011088378707773851, 'xgb_n_estimators': 472, 'xgb_max_depth': 12, 'xgb_subsample': 0.9095800473345252, 'xgb_colsample_bytree': 0.7840914996161625, 'xgb_reg_alpha': 0.033147189552712876, 'xgb_reg_lambda': 1.0134409651436559e-08, 'threshold': 0.49711074576500314}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 95 for F0.5 optimization\n",
      "INFO:root:Trial 95 completed with average F0.5 Score: 0.6846600007459933\n",
      "[I 2024-10-02 14:36:59,323] Trial 95 finished with value: 0.6846600007459933 and parameters: {'xgb_learning_rate': 0.016473599623089495, 'xgb_n_estimators': 459, 'xgb_max_depth': 11, 'xgb_subsample': 0.9385036181915843, 'xgb_colsample_bytree': 0.7349857757482554, 'xgb_reg_alpha': 0.009686178904914994, 'xgb_reg_lambda': 3.443383068489292e-08, 'threshold': 0.5805636674120258}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 96 for F0.5 optimization\n",
      "INFO:root:Trial 96 completed with average F0.5 Score: 0.6806729781301822\n",
      "[I 2024-10-02 14:37:23,380] Trial 96 finished with value: 0.6806729781301822 and parameters: {'xgb_learning_rate': 0.013151931858659297, 'xgb_n_estimators': 499, 'xgb_max_depth': 12, 'xgb_subsample': 0.8861989962133332, 'xgb_colsample_bytree': 0.6964898560050138, 'xgb_reg_alpha': 0.07687523773902143, 'xgb_reg_lambda': 1.802534131708649e-08, 'threshold': 0.6317082951435833}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 97 for F0.5 optimization\n",
      "INFO:root:Trial 97 completed with average F0.5 Score: 0.6869721835966219\n",
      "[I 2024-10-02 14:37:55,027] Trial 97 finished with value: 0.6869721835966219 and parameters: {'xgb_learning_rate': 0.008996066289894834, 'xgb_n_estimators': 405, 'xgb_max_depth': 11, 'xgb_subsample': 0.8686512044721633, 'xgb_colsample_bytree': 0.7182022104406812, 'xgb_reg_alpha': 0.01949823086372993, 'xgb_reg_lambda': 6.159832095002052e-08, 'threshold': 0.5331372888240113}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 98 for F0.5 optimization\n",
      "INFO:root:Trial 98 completed with average F0.5 Score: 0.686927487466245\n",
      "[I 2024-10-02 14:38:24,246] Trial 98 finished with value: 0.686927487466245 and parameters: {'xgb_learning_rate': 0.009744551996406644, 'xgb_n_estimators': 354, 'xgb_max_depth': 11, 'xgb_subsample': 0.9125113497946538, 'xgb_colsample_bytree': 0.7060603844832319, 'xgb_reg_alpha': 0.020035026644434257, 'xgb_reg_lambda': 5.16315496613699e-07, 'threshold': 0.5295606373731472}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 99 for F0.5 optimization\n",
      "INFO:root:Trial 99 completed with average F0.5 Score: 0.6865789329589631\n",
      "[I 2024-10-02 14:38:52,390] Trial 99 finished with value: 0.6865789329589631 and parameters: {'xgb_learning_rate': 0.009414926108406371, 'xgb_n_estimators': 403, 'xgb_max_depth': 10, 'xgb_subsample': 0.9191685311211509, 'xgb_colsample_bytree': 0.7184277107301708, 'xgb_reg_alpha': 0.013355962972461097, 'xgb_reg_lambda': 1.8322602738859865e-07, 'threshold': 0.5210721291181042}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 100 for F0.5 optimization\n",
      "INFO:root:Trial 100 completed with average F0.5 Score: 0.684991754417479\n",
      "INFO:root:Message sent to channel #hyperparametertuning: Trial 100 completed with average F0.5 Score: 0.684991754417479\n",
      "[I 2024-10-02 14:39:26,350] Trial 100 finished with value: 0.684991754417479 and parameters: {'xgb_learning_rate': 0.007979932971101937, 'xgb_n_estimators': 376, 'xgb_max_depth': 11, 'xgb_subsample': 0.9268576466595989, 'xgb_colsample_bytree': 0.6957772149958591, 'xgb_reg_alpha': 0.020147739277386514, 'xgb_reg_lambda': 3.761316607540152e-07, 'threshold': 0.5037227724591317}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 101 for F0.5 optimization\n",
      "INFO:root:Trial 101 completed with average F0.5 Score: 0.6877056161841958\n",
      "[I 2024-10-02 14:39:54,819] Trial 101 finished with value: 0.6877056161841958 and parameters: {'xgb_learning_rate': 0.010049183435357982, 'xgb_n_estimators': 355, 'xgb_max_depth': 11, 'xgb_subsample': 0.918369065016371, 'xgb_colsample_bytree': 0.7052709012084089, 'xgb_reg_alpha': 0.012633959240173718, 'xgb_reg_lambda': 1.3199582388392119e-07, 'threshold': 0.5316197882883865}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 102 for F0.5 optimization\n",
      "INFO:root:Trial 102 completed with average F0.5 Score: 0.6854591702686076\n",
      "[I 2024-10-02 14:40:19,420] Trial 102 finished with value: 0.6854591702686076 and parameters: {'xgb_learning_rate': 0.01184395165869473, 'xgb_n_estimators': 346, 'xgb_max_depth': 11, 'xgb_subsample': 0.9388190537839937, 'xgb_colsample_bytree': 0.711904604937915, 'xgb_reg_alpha': 0.006164406575763039, 'xgb_reg_lambda': 1.325276689037014e-07, 'threshold': 0.5381496722276274}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 103 for F0.5 optimization\n",
      "INFO:root:Trial 103 completed with average F0.5 Score: 0.6859833378023554\n",
      "[I 2024-10-02 14:40:52,456] Trial 103 finished with value: 0.6859833378023554 and parameters: {'xgb_learning_rate': 0.007066869093976181, 'xgb_n_estimators': 356, 'xgb_max_depth': 11, 'xgb_subsample': 0.9020107426443409, 'xgb_colsample_bytree': 0.7250772098690363, 'xgb_reg_alpha': 0.009929131461462659, 'xgb_reg_lambda': 7.423101537923821e-08, 'threshold': 0.5246146557867234}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 104 for F0.5 optimization\n",
      "INFO:root:Trial 104 completed with average F0.5 Score: 0.681905646695753\n",
      "[I 2024-10-02 14:41:18,520] Trial 104 finished with value: 0.681905646695753 and parameters: {'xgb_learning_rate': 0.0060685333884041934, 'xgb_n_estimators': 321, 'xgb_max_depth': 10, 'xgb_subsample': 0.9138316013980469, 'xgb_colsample_bytree': 0.7027584115414937, 'xgb_reg_alpha': 0.020754125869851973, 'xgb_reg_lambda': 1.03612776676862e-07, 'threshold': 0.48274243774483866}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 105 for F0.5 optimization\n",
      "INFO:root:Trial 105 completed with average F0.5 Score: 0.6874739470557435\n",
      "[I 2024-10-02 14:41:44,679] Trial 105 finished with value: 0.6874739470557435 and parameters: {'xgb_learning_rate': 0.011307862755183737, 'xgb_n_estimators': 302, 'xgb_max_depth': 11, 'xgb_subsample': 0.8898000109280421, 'xgb_colsample_bytree': 0.6720443839169096, 'xgb_reg_alpha': 0.034601803264332966, 'xgb_reg_lambda': 2.782378886652065e-08, 'threshold': 0.567146359277381}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 106 for F0.5 optimization\n",
      "INFO:root:Trial 106 completed with average F0.5 Score: 0.6871696424423035\n",
      "[I 2024-10-02 14:42:02,516] Trial 106 finished with value: 0.6871696424423035 and parameters: {'xgb_learning_rate': 0.01855941969981187, 'xgb_n_estimators': 304, 'xgb_max_depth': 11, 'xgb_subsample': 0.8863790445745076, 'xgb_colsample_bytree': 0.6730220761565351, 'xgb_reg_alpha': 0.004562124544464854, 'xgb_reg_lambda': 5.915071560550092e-07, 'threshold': 0.5686640309836509}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 107 for F0.5 optimization\n",
      "INFO:root:Trial 107 completed with average F0.5 Score: 0.6866251288648281\n",
      "[I 2024-10-02 14:42:18,904] Trial 107 finished with value: 0.6866251288648281 and parameters: {'xgb_learning_rate': 0.019405062906315766, 'xgb_n_estimators': 330, 'xgb_max_depth': 10, 'xgb_subsample': 0.8922543267025574, 'xgb_colsample_bytree': 0.6835005707597901, 'xgb_reg_alpha': 0.004104656467867203, 'xgb_reg_lambda': 5.652249970975079e-07, 'threshold': 0.5700368287766758}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 108 for F0.5 optimization\n",
      "INFO:root:Trial 108 completed with average F0.5 Score: 0.6849756942346505\n",
      "[I 2024-10-02 14:42:33,314] Trial 108 finished with value: 0.6849756942346505 and parameters: {'xgb_learning_rate': 0.025251107084098872, 'xgb_n_estimators': 301, 'xgb_max_depth': 11, 'xgb_subsample': 0.8618326657361715, 'xgb_colsample_bytree': 0.6726257315372062, 'xgb_reg_alpha': 0.016610481050223353, 'xgb_reg_lambda': 2.5603296736413487e-07, 'threshold': 0.5413405503813962}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 109 for F0.5 optimization\n",
      "INFO:root:Trial 109 completed with average F0.5 Score: 0.6849308656956995\n",
      "[I 2024-10-02 14:42:51,982] Trial 109 finished with value: 0.6849308656956995 and parameters: {'xgb_learning_rate': 0.011169999244434724, 'xgb_n_estimators': 279, 'xgb_max_depth': 9, 'xgb_subsample': 0.9315625563233599, 'xgb_colsample_bytree': 0.6517555998750629, 'xgb_reg_alpha': 0.005634956640554917, 'xgb_reg_lambda': 1.9646812029221663e-06, 'threshold': 0.5124072857155351}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 110 for F0.5 optimization\n",
      "INFO:root:Trial 110 completed with average F0.5 Score: 0.682993335303152\n",
      "[I 2024-10-02 14:43:07,862] Trial 110 finished with value: 0.682993335303152 and parameters: {'xgb_learning_rate': 0.021382712295848386, 'xgb_n_estimators': 313, 'xgb_max_depth': 11, 'xgb_subsample': 0.8789657595704876, 'xgb_colsample_bytree': 0.6939488832094062, 'xgb_reg_alpha': 0.012551263096108578, 'xgb_reg_lambda': 4.184430430741635e-08, 'threshold': 0.49270064355735166}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 111 for F0.5 optimization\n",
      "INFO:root:Trial 111 completed with average F0.5 Score: 0.6833430935237896\n",
      "[I 2024-10-02 14:43:27,105] Trial 111 finished with value: 0.6833430935237896 and parameters: {'xgb_learning_rate': 0.016485957387106162, 'xgb_n_estimators': 288, 'xgb_max_depth': 11, 'xgb_subsample': 0.8937800947132608, 'xgb_colsample_bytree': 0.6705375468662222, 'xgb_reg_alpha': 0.00819897397181178, 'xgb_reg_lambda': 1.8146355558311544e-07, 'threshold': 0.547883968511317}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 112 for F0.5 optimization\n",
      "INFO:root:Trial 112 completed with average F0.5 Score: 0.6859108590470308\n",
      "[I 2024-10-02 14:43:49,904] Trial 112 finished with value: 0.6859108590470308 and parameters: {'xgb_learning_rate': 0.01365937653743408, 'xgb_n_estimators': 256, 'xgb_max_depth': 11, 'xgb_subsample': 0.9240331873573049, 'xgb_colsample_bytree': 0.6819591571556739, 'xgb_reg_alpha': 0.0016683434540419094, 'xgb_reg_lambda': 2.7918772430595026e-08, 'threshold': 0.5761293369629354}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 113 for F0.5 optimization\n",
      "INFO:root:Trial 113 completed with average F0.5 Score: 0.6867681138719581\n",
      "[I 2024-10-02 14:44:13,785] Trial 113 finished with value: 0.6867681138719581 and parameters: {'xgb_learning_rate': 0.009310746576252301, 'xgb_n_estimators': 303, 'xgb_max_depth': 10, 'xgb_subsample': 0.8523054464170432, 'xgb_colsample_bytree': 0.7051472735193431, 'xgb_reg_alpha': 0.003272872538963929, 'xgb_reg_lambda': 9.081959852644078e-07, 'threshold': 0.5257209564175106}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 114 for F0.5 optimization\n",
      "INFO:root:Trial 114 completed with average F0.5 Score: 0.6773904260155161\n",
      "[I 2024-10-02 14:44:30,765] Trial 114 finished with value: 0.6773904260155161 and parameters: {'xgb_learning_rate': 0.018695759916745006, 'xgb_n_estimators': 381, 'xgb_max_depth': 5, 'xgb_subsample': 0.9122205683244435, 'xgb_colsample_bytree': 0.7128326704046987, 'xgb_reg_alpha': 0.033186483261555856, 'xgb_reg_lambda': 1.1881886534246081e-07, 'threshold': 0.5630310037167525}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 115 for F0.5 optimization\n",
      "INFO:root:Trial 115 completed with average F0.5 Score: 0.6847458403633644\n",
      "[I 2024-10-02 14:44:57,952] Trial 115 finished with value: 0.6847458403633644 and parameters: {'xgb_learning_rate': 0.010738762036982673, 'xgb_n_estimators': 367, 'xgb_max_depth': 11, 'xgb_subsample': 0.8705537066092081, 'xgb_colsample_bytree': 0.6568188468933834, 'xgb_reg_alpha': 0.02291453162626971, 'xgb_reg_lambda': 7.033158351582211e-08, 'threshold': 0.6103253293806671}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 116 for F0.5 optimization\n",
      "INFO:root:Trial 116 completed with average F0.5 Score: 0.6835272331936937\n",
      "[I 2024-10-02 14:45:10,606] Trial 116 finished with value: 0.6835272331936937 and parameters: {'xgb_learning_rate': 0.029011006454201613, 'xgb_n_estimators': 346, 'xgb_max_depth': 11, 'xgb_subsample': 0.9536752102600522, 'xgb_colsample_bytree': 0.7238055272902031, 'xgb_reg_alpha': 0.005396516976344395, 'xgb_reg_lambda': 3.109162931839093e-07, 'threshold': 0.5433345890195113}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 117 for F0.5 optimization\n",
      "INFO:root:Trial 117 completed with average F0.5 Score: 0.6871785950424496\n",
      "[I 2024-10-02 14:45:31,008] Trial 117 finished with value: 0.6871785950424496 and parameters: {'xgb_learning_rate': 0.01542265256236788, 'xgb_n_estimators': 271, 'xgb_max_depth': 11, 'xgb_subsample': 0.8860367834362158, 'xgb_colsample_bytree': 0.6421273839362415, 'xgb_reg_alpha': 0.011652821243246438, 'xgb_reg_lambda': 4.233404790286679e-08, 'threshold': 0.5885311865802305}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 118 for F0.5 optimization\n",
      "INFO:root:Trial 118 completed with average F0.5 Score: 0.6869014998499081\n",
      "[I 2024-10-02 14:45:51,091] Trial 118 finished with value: 0.6869014998499081 and parameters: {'xgb_learning_rate': 0.015769024967570686, 'xgb_n_estimators': 263, 'xgb_max_depth': 11, 'xgb_subsample': 0.8831937705740809, 'xgb_colsample_bytree': 0.6455004253445251, 'xgb_reg_alpha': 0.012787179522987406, 'xgb_reg_lambda': 3.8300767199195516e-08, 'threshold': 0.5841784859600178}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 119 for F0.5 optimization\n",
      "INFO:root:Trial 119 completed with average F0.5 Score: 0.6852803059325393\n",
      "[I 2024-10-02 14:46:15,696] Trial 119 finished with value: 0.6852803059325393 and parameters: {'xgb_learning_rate': 0.008717464194509573, 'xgb_n_estimators': 261, 'xgb_max_depth': 11, 'xgb_subsample': 0.8811184049187273, 'xgb_colsample_bytree': 0.6403373268625812, 'xgb_reg_alpha': 0.011454544154518922, 'xgb_reg_lambda': 4.3896621413661054e-08, 'threshold': 0.5003941512069087}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 120 for F0.5 optimization\n",
      "INFO:root:Trial 120 completed with average F0.5 Score: 0.6813090078427555\n",
      "[I 2024-10-02 14:46:34,398] Trial 120 finished with value: 0.6813090078427555 and parameters: {'xgb_learning_rate': 0.014364542232665492, 'xgb_n_estimators': 244, 'xgb_max_depth': 10, 'xgb_subsample': 0.9443433511102609, 'xgb_colsample_bytree': 0.6711269165758147, 'xgb_reg_alpha': 0.03916535428432728, 'xgb_reg_lambda': 4.529970804501046e-07, 'threshold': 0.621305850826954}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 121 for F0.5 optimization\n",
      "INFO:root:Trial 121 completed with average F0.5 Score: 0.6867256860224098\n",
      "[I 2024-10-02 14:46:49,435] Trial 121 finished with value: 0.6867256860224098 and parameters: {'xgb_learning_rate': 0.023331251769034837, 'xgb_n_estimators': 270, 'xgb_max_depth': 11, 'xgb_subsample': 0.8968295700660266, 'xgb_colsample_bytree': 0.6464725112634608, 'xgb_reg_alpha': 0.015786174680408046, 'xgb_reg_lambda': 2.7622895674347283e-08, 'threshold': 0.5881435390011429}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 122 for F0.5 optimization\n",
      "INFO:root:Trial 122 completed with average F0.5 Score: 0.6863619760840863\n",
      "[I 2024-10-02 14:47:11,109] Trial 122 finished with value: 0.6863619760840863 and parameters: {'xgb_learning_rate': 0.012035035794208204, 'xgb_n_estimators': 232, 'xgb_max_depth': 11, 'xgb_subsample': 0.917078255206059, 'xgb_colsample_bytree': 0.6299681148097431, 'xgb_reg_alpha': 0.008262790327059814, 'xgb_reg_lambda': 4.586922464618517e-08, 'threshold': 0.5687921705491825}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 123 for F0.5 optimization\n",
      "INFO:root:Trial 123 completed with average F0.5 Score: 0.6849367741541801\n",
      "[I 2024-10-02 14:47:30,194] Trial 123 finished with value: 0.6849367741541801 and parameters: {'xgb_learning_rate': 0.016410461353281277, 'xgb_n_estimators': 285, 'xgb_max_depth': 11, 'xgb_subsample': 0.8862829221801238, 'xgb_colsample_bytree': 0.6627834965520338, 'xgb_reg_alpha': 0.02272976569666845, 'xgb_reg_lambda': 7.648040234344548e-08, 'threshold': 0.6039458594522068}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 124 for F0.5 optimization\n",
      "INFO:root:Trial 124 completed with average F0.5 Score: 0.6867965627737077\n",
      "[I 2024-10-02 14:47:47,686] Trial 124 finished with value: 0.6867965627737077 and parameters: {'xgb_learning_rate': 0.01770048619074834, 'xgb_n_estimators': 296, 'xgb_max_depth': 10, 'xgb_subsample': 0.9049866763605259, 'xgb_colsample_bytree': 0.6772721247616824, 'xgb_reg_alpha': 0.002701015805835718, 'xgb_reg_lambda': 2.3228127383665058e-08, 'threshold': 0.5321083778936659}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 125 for F0.5 optimization\n",
      "INFO:root:Trial 125 completed with average F0.5 Score: 0.6869378267785774\n",
      "[I 2024-10-02 14:48:11,758] Trial 125 finished with value: 0.6869378267785774 and parameters: {'xgb_learning_rate': 0.01260326808187468, 'xgb_n_estimators': 409, 'xgb_max_depth': 11, 'xgb_subsample': 0.8376438755704615, 'xgb_colsample_bytree': 0.6911847970215056, 'xgb_reg_alpha': 0.03213333655956922, 'xgb_reg_lambda': 1.2082675006541653e-07, 'threshold': 0.5844920897347889}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 126 for F0.5 optimization\n",
      "INFO:root:Trial 126 completed with average F0.5 Score: 0.6869621671970585\n",
      "[I 2024-10-02 14:48:40,550] Trial 126 finished with value: 0.6869621671970585 and parameters: {'xgb_learning_rate': 0.00975351968032302, 'xgb_n_estimators': 327, 'xgb_max_depth': 11, 'xgb_subsample': 0.8425115242096048, 'xgb_colsample_bytree': 0.6866734852859931, 'xgb_reg_alpha': 0.055413244174530814, 'xgb_reg_lambda': 1.482307470445946e-07, 'threshold': 0.5572132024988201}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 127 for F0.5 optimization\n",
      "INFO:root:Trial 127 completed with average F0.5 Score: 0.685286074043874\n",
      "[I 2024-10-02 14:49:08,610] Trial 127 finished with value: 0.685286074043874 and parameters: {'xgb_learning_rate': 0.009949820465761218, 'xgb_n_estimators': 323, 'xgb_max_depth': 11, 'xgb_subsample': 0.8396265992315407, 'xgb_colsample_bytree': 0.6947429432370716, 'xgb_reg_alpha': 0.05200708996772725, 'xgb_reg_lambda': 1.1931757360011072e-07, 'threshold': 0.54935607015792}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 128 for F0.5 optimization\n",
      "INFO:root:Trial 128 completed with average F0.5 Score: 0.6868287274934867\n",
      "[I 2024-10-02 14:49:43,489] Trial 128 finished with value: 0.6868287274934867 and parameters: {'xgb_learning_rate': 0.008042146574588406, 'xgb_n_estimators': 394, 'xgb_max_depth': 11, 'xgb_subsample': 0.8654799084783457, 'xgb_colsample_bytree': 0.6667271493482076, 'xgb_reg_alpha': 0.10280714625826182, 'xgb_reg_lambda': 1.9710721483379266e-07, 'threshold': 0.5829692896813177}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 129 for F0.5 optimization\n",
      "INFO:root:Trial 129 completed with average F0.5 Score: 0.6863410027396641\n",
      "[I 2024-10-02 14:50:07,640] Trial 129 finished with value: 0.6863410027396641 and parameters: {'xgb_learning_rate': 0.012640423837616682, 'xgb_n_estimators': 315, 'xgb_max_depth': 11, 'xgb_subsample': 0.8267101240072408, 'xgb_colsample_bytree': 0.630438402279124, 'xgb_reg_alpha': 0.03046616372061837, 'xgb_reg_lambda': 2.832264226690219e-07, 'threshold': 0.5137471310980832}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 130 for F0.5 optimization\n",
      "INFO:root:Trial 130 completed with average F0.5 Score: 0.6813761736974655\n",
      "[I 2024-10-02 14:50:33,396] Trial 130 finished with value: 0.6813761736974655 and parameters: {'xgb_learning_rate': 0.00921030129998209, 'xgb_n_estimators': 334, 'xgb_max_depth': 10, 'xgb_subsample': 0.8378170658086291, 'xgb_colsample_bytree': 0.6767329120144128, 'xgb_reg_alpha': 0.1634289809959213, 'xgb_reg_lambda': 1.515166492707004e-07, 'threshold': 0.47630331178970486}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 131 for F0.5 optimization\n",
      "INFO:root:Trial 131 completed with average F0.5 Score: 0.6876218188390704\n",
      "[I 2024-10-02 14:51:08,128] Trial 131 finished with value: 0.6876218188390704 and parameters: {'xgb_learning_rate': 0.007572762614597657, 'xgb_n_estimators': 389, 'xgb_max_depth': 11, 'xgb_subsample': 0.8758703639142708, 'xgb_colsample_bytree': 0.6638639995820713, 'xgb_reg_alpha': 0.10682196514177332, 'xgb_reg_lambda': 1.9705021508175834e-07, 'threshold': 0.5627666710282756}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 132 for F0.5 optimization\n",
      "INFO:root:Trial 132 completed with average F0.5 Score: 0.6872203332821084\n",
      "[I 2024-10-02 14:51:35,661] Trial 132 finished with value: 0.6872203332821084 and parameters: {'xgb_learning_rate': 0.010704691365030352, 'xgb_n_estimators': 408, 'xgb_max_depth': 11, 'xgb_subsample': 0.8740823365909783, 'xgb_colsample_bytree': 0.6616021055551649, 'xgb_reg_alpha': 0.04173550396193338, 'xgb_reg_lambda': 8.767740172731119e-08, 'threshold': 0.5569028668751612}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 133 for F0.5 optimization\n",
      "INFO:root:Trial 133 completed with average F0.5 Score: 0.685721644252787\n",
      "[I 2024-10-02 14:52:04,031] Trial 133 finished with value: 0.685721644252787 and parameters: {'xgb_learning_rate': 0.010474055629122585, 'xgb_n_estimators': 408, 'xgb_max_depth': 11, 'xgb_subsample': 0.8498609675454716, 'xgb_colsample_bytree': 0.6615705985361346, 'xgb_reg_alpha': 0.06561905134240002, 'xgb_reg_lambda': 6.183594617885275e-07, 'threshold': 0.5526386264775327}. Best is trial 41 with value: 0.6877094220501249.\n",
      "INFO:root:Starting trial 134 for F0.5 optimization\n",
      "INFO:root:Trial 134 completed with average F0.5 Score: 0.6879059977232419\n",
      "[I 2024-10-02 14:52:39,233] Trial 134 finished with value: 0.6879059977232419 and parameters: {'xgb_learning_rate': 0.007605314629617513, 'xgb_n_estimators': 391, 'xgb_max_depth': 11, 'xgb_subsample': 0.8596587680670658, 'xgb_colsample_bytree': 0.6860567074582623, 'xgb_reg_alpha': 0.12540257259968168, 'xgb_reg_lambda': 9.627575795535794e-08, 'threshold': 0.5284133176843421}. Best is trial 134 with value: 0.6879059977232419.\n",
      "INFO:root:Starting trial 135 for F0.5 optimization\n",
      "INFO:root:Trial 135 completed with average F0.5 Score: 0.6874122742140465\n",
      "[I 2024-10-02 14:53:12,064] Trial 135 finished with value: 0.6874122742140465 and parameters: {'xgb_learning_rate': 0.007588001405901747, 'xgb_n_estimators': 365, 'xgb_max_depth': 11, 'xgb_subsample': 0.8551289680263092, 'xgb_colsample_bytree': 0.6941406306962802, 'xgb_reg_alpha': 0.1352881790443026, 'xgb_reg_lambda': 8.619719931551218e-08, 'threshold': 0.5601248438391614}. Best is trial 134 with value: 0.6879059977232419.\n",
      "INFO:root:Starting trial 136 for F0.5 optimization\n",
      "INFO:root:Trial 136 completed with average F0.5 Score: 0.6877552497608459\n",
      "[I 2024-10-02 14:53:48,838] Trial 136 finished with value: 0.6877552497608459 and parameters: {'xgb_learning_rate': 0.004631775370043994, 'xgb_n_estimators': 388, 'xgb_max_depth': 11, 'xgb_subsample': 0.859937075399498, 'xgb_colsample_bytree': 0.6561166404546862, 'xgb_reg_alpha': 0.15497661144270525, 'xgb_reg_lambda': 8.398842273129223e-08, 'threshold': 0.5620847167787563}. Best is trial 134 with value: 0.6879059977232419.\n",
      "INFO:root:Starting trial 137 for F0.5 optimization\n",
      "INFO:root:Trial 137 completed with average F0.5 Score: 0.6856157495426181\n",
      "[I 2024-10-02 14:54:25,277] Trial 137 finished with value: 0.6856157495426181 and parameters: {'xgb_learning_rate': 0.005057277239139151, 'xgb_n_estimators': 388, 'xgb_max_depth': 11, 'xgb_subsample': 0.8552321833040908, 'xgb_colsample_bytree': 0.6568132779079996, 'xgb_reg_alpha': 0.1335076639610976, 'xgb_reg_lambda': 8.049333546483145e-08, 'threshold': 0.519805744771148}. Best is trial 134 with value: 0.6879059977232419.\n",
      "INFO:root:Starting trial 138 for F0.5 optimization\n",
      "INFO:root:Trial 138 completed with average F0.5 Score: 0.6857917559801429\n",
      "[I 2024-10-02 14:54:58,985] Trial 138 finished with value: 0.6857917559801429 and parameters: {'xgb_learning_rate': 0.00605328211745527, 'xgb_n_estimators': 363, 'xgb_max_depth': 11, 'xgb_subsample': 0.8670508389700513, 'xgb_colsample_bytree': 0.6356310779108364, 'xgb_reg_alpha': 0.22420807435942863, 'xgb_reg_lambda': 6.064691741024295e-08, 'threshold': 0.5418512633142937}. Best is trial 134 with value: 0.6879059977232419.\n",
      "INFO:root:Starting trial 139 for F0.5 optimization\n",
      "INFO:root:Trial 139 completed with average F0.5 Score: 0.6875472238886038\n",
      "[I 2024-10-02 14:55:28,372] Trial 139 finished with value: 0.6875472238886038 and parameters: {'xgb_learning_rate': 0.0075232833706393885, 'xgb_n_estimators': 382, 'xgb_max_depth': 10, 'xgb_subsample': 0.8564624573907992, 'xgb_colsample_bytree': 0.664230155889183, 'xgb_reg_alpha': 0.13177811397769756, 'xgb_reg_lambda': 2.1918727878273628e-07, 'threshold': 0.5647657433108115}. Best is trial 134 with value: 0.6879059977232419.\n",
      "INFO:root:Starting trial 140 for F0.5 optimization\n",
      "INFO:root:Trial 140 completed with average F0.5 Score: 0.6850770633043588\n",
      "[I 2024-10-02 14:55:58,606] Trial 140 finished with value: 0.6850770633043588 and parameters: {'xgb_learning_rate': 0.007371791636310195, 'xgb_n_estimators': 389, 'xgb_max_depth': 10, 'xgb_subsample': 0.8564119311902468, 'xgb_colsample_bytree': 0.6676724114604049, 'xgb_reg_alpha': 0.5131689777772588, 'xgb_reg_lambda': 1.8792688000054607e-07, 'threshold': 0.5995942162092204}. Best is trial 134 with value: 0.6879059977232419.\n",
      "INFO:root:Starting trial 141 for F0.5 optimization\n",
      "INFO:root:Trial 141 completed with average F0.5 Score: 0.6881538973844225\n",
      "[I 2024-10-02 14:56:35,369] Trial 141 finished with value: 0.6881538973844225 and parameters: {'xgb_learning_rate': 0.006608590221274457, 'xgb_n_estimators': 404, 'xgb_max_depth': 11, 'xgb_subsample': 0.8736880089699716, 'xgb_colsample_bytree': 0.6511019131064728, 'xgb_reg_alpha': 0.12091478502587398, 'xgb_reg_lambda': 1.0550966746332082e-07, 'threshold': 0.5622134912270453}. Best is trial 141 with value: 0.6881538973844225.\n",
      "INFO:root:Starting trial 142 for F0.5 optimization\n",
      "INFO:root:Trial 142 completed with average F0.5 Score: 0.6885066436727494\n",
      "[I 2024-10-02 14:57:10,532] Trial 142 finished with value: 0.6885066436727494 and parameters: {'xgb_learning_rate': 0.006477764489791831, 'xgb_n_estimators': 383, 'xgb_max_depth': 11, 'xgb_subsample': 0.8807785012120731, 'xgb_colsample_bytree': 0.6521045028753499, 'xgb_reg_alpha': 0.234184686669641, 'xgb_reg_lambda': 9.083653647297892e-08, 'threshold': 0.563504272038456}. Best is trial 142 with value: 0.6885066436727494.\n",
      "INFO:root:Starting trial 143 for F0.5 optimization\n",
      "INFO:root:Trial 143 completed with average F0.5 Score: 0.6873758186414052\n",
      "[I 2024-10-02 14:57:45,845] Trial 143 finished with value: 0.6873758186414052 and parameters: {'xgb_learning_rate': 0.0049336916518159905, 'xgb_n_estimators': 373, 'xgb_max_depth': 11, 'xgb_subsample': 0.8735836937551997, 'xgb_colsample_bytree': 0.6239228887219486, 'xgb_reg_alpha': 0.21193421643654287, 'xgb_reg_lambda': 1.0655799044896923e-07, 'threshold': 0.5632916414026938}. Best is trial 142 with value: 0.6885066436727494.\n",
      "INFO:root:Starting trial 144 for F0.5 optimization\n",
      "INFO:root:Trial 144 completed with average F0.5 Score: 0.6866185558526475\n",
      "[I 2024-10-02 14:58:21,614] Trial 144 finished with value: 0.6866185558526475 and parameters: {'xgb_learning_rate': 0.004453608722854186, 'xgb_n_estimators': 376, 'xgb_max_depth': 11, 'xgb_subsample': 0.8789509338049254, 'xgb_colsample_bytree': 0.6202114947867845, 'xgb_reg_alpha': 0.25892084722627523, 'xgb_reg_lambda': 2.50463582527913e-07, 'threshold': 0.5713232562294315}. Best is trial 142 with value: 0.6885066436727494.\n",
      "INFO:root:Starting trial 145 for F0.5 optimization\n",
      "INFO:root:Trial 145 completed with average F0.5 Score: 0.6808248284988877\n",
      "[I 2024-10-02 14:58:42,635] Trial 145 finished with value: 0.6808248284988877 and parameters: {'xgb_learning_rate': 0.004991919331513072, 'xgb_n_estimators': 370, 'xgb_max_depth': 8, 'xgb_subsample': 0.8598688950794742, 'xgb_colsample_bytree': 0.6434742130689012, 'xgb_reg_alpha': 0.17809949953606932, 'xgb_reg_lambda': 8.822683899712015e-08, 'threshold': 0.558455116946701}. Best is trial 142 with value: 0.6885066436727494.\n",
      "INFO:root:Starting trial 146 for F0.5 optimization\n",
      "INFO:root:Trial 146 completed with average F0.5 Score: 0.6813859127212857\n",
      "[I 2024-10-02 14:59:18,253] Trial 146 finished with value: 0.6813859127212857 and parameters: {'xgb_learning_rate': 0.005762867946085163, 'xgb_n_estimators': 385, 'xgb_max_depth': 11, 'xgb_subsample': 0.8485200393017858, 'xgb_colsample_bytree': 0.6488064218072189, 'xgb_reg_alpha': 0.12857894448168414, 'xgb_reg_lambda': 3.7148181875340226e-07, 'threshold': 0.6248729340160948}. Best is trial 142 with value: 0.6885066436727494.\n",
      "INFO:root:Starting trial 147 for F0.5 optimization\n",
      "INFO:root:Trial 147 completed with average F0.5 Score: 0.6812188692060703\n",
      "[I 2024-10-02 14:59:56,605] Trial 147 finished with value: 0.6812188692060703 and parameters: {'xgb_learning_rate': 0.004034081190418406, 'xgb_n_estimators': 398, 'xgb_max_depth': 11, 'xgb_subsample': 0.8760809816848262, 'xgb_colsample_bytree': 0.6571660032661479, 'xgb_reg_alpha': 0.08748150886354544, 'xgb_reg_lambda': 1.0168110961105243e-07, 'threshold': 0.5989190967149444}. Best is trial 142 with value: 0.6885066436727494.\n",
      "INFO:root:Starting trial 148 for F0.5 optimization\n",
      "INFO:root:Trial 148 completed with average F0.5 Score: 0.688637380527025\n",
      "[I 2024-10-02 15:00:34,245] Trial 148 finished with value: 0.688637380527025 and parameters: {'xgb_learning_rate': 0.0067096503859230055, 'xgb_n_estimators': 420, 'xgb_max_depth': 11, 'xgb_subsample': 0.8667580027254321, 'xgb_colsample_bytree': 0.6316967772537754, 'xgb_reg_alpha': 0.36474077756186196, 'xgb_reg_lambda': 1.7465954334892753e-07, 'threshold': 0.5694040946452658}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 149 for F0.5 optimization\n",
      "INFO:root:Trial 149 completed with average F0.5 Score: 0.6831846946074454\n",
      "[I 2024-10-02 15:01:06,710] Trial 149 finished with value: 0.6831846946074454 and parameters: {'xgb_learning_rate': 0.006491577365402397, 'xgb_n_estimators': 421, 'xgb_max_depth': 10, 'xgb_subsample': 0.8629952874520732, 'xgb_colsample_bytree': 0.6261778406340017, 'xgb_reg_alpha': 0.4010780665596233, 'xgb_reg_lambda': 2.0945493027687705e-07, 'threshold': 0.6121445978940188}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 150 for F0.5 optimization\n",
      "INFO:root:Trial 150 completed with average F0.5 Score: 0.6862294066884611\n",
      "[I 2024-10-02 15:01:41,344] Trial 150 finished with value: 0.6862294066884611 and parameters: {'xgb_learning_rate': 0.0054404848005705645, 'xgb_n_estimators': 376, 'xgb_max_depth': 11, 'xgb_subsample': 0.8197516585678831, 'xgb_colsample_bytree': 0.6056280892162723, 'xgb_reg_alpha': 0.2081815648116989, 'xgb_reg_lambda': 1.0925574029164295e-07, 'threshold': 0.5488642358707962}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 151 for F0.5 optimization\n",
      "INFO:root:Trial 151 completed with average F0.5 Score: 0.6884046549628439\n",
      "[I 2024-10-02 15:02:14,028] Trial 151 finished with value: 0.6884046549628439 and parameters: {'xgb_learning_rate': 0.0072727068591885114, 'xgb_n_estimators': 359, 'xgb_max_depth': 11, 'xgb_subsample': 0.8760921047605734, 'xgb_colsample_bytree': 0.6381353490552728, 'xgb_reg_alpha': 0.6353436139015015, 'xgb_reg_lambda': 1.5378678533546508e-07, 'threshold': 0.5658874928521779}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 152 for F0.5 optimization\n",
      "INFO:root:Trial 152 completed with average F0.5 Score: 0.6880848381995925\n",
      "[I 2024-10-02 15:02:47,117] Trial 152 finished with value: 0.6880848381995925 and parameters: {'xgb_learning_rate': 0.006408997879974658, 'xgb_n_estimators': 361, 'xgb_max_depth': 11, 'xgb_subsample': 0.866633417678666, 'xgb_colsample_bytree': 0.6420437525614883, 'xgb_reg_alpha': 0.3821861729431513, 'xgb_reg_lambda': 3.414548335901264e-07, 'threshold': 0.5653714676392568}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 153 for F0.5 optimization\n",
      "INFO:root:Trial 153 completed with average F0.5 Score: 0.688159097919661\n",
      "[I 2024-10-02 15:03:19,725] Trial 153 finished with value: 0.688159097919661 and parameters: {'xgb_learning_rate': 0.006989904104385219, 'xgb_n_estimators': 358, 'xgb_max_depth': 11, 'xgb_subsample': 0.8734771194297722, 'xgb_colsample_bytree': 0.6355969078663452, 'xgb_reg_alpha': 0.8081178887536974, 'xgb_reg_lambda': 2.0480462318689448e-07, 'threshold': 0.5685598157844226}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 154 for F0.5 optimization\n",
      "INFO:root:Trial 154 completed with average F0.5 Score: 0.6876270710621691\n",
      "[I 2024-10-02 15:03:52,065] Trial 154 finished with value: 0.6876270710621691 and parameters: {'xgb_learning_rate': 0.007291285141611196, 'xgb_n_estimators': 359, 'xgb_max_depth': 11, 'xgb_subsample': 0.8514170214505795, 'xgb_colsample_bytree': 0.6379133438086244, 'xgb_reg_alpha': 0.7179308060231312, 'xgb_reg_lambda': 3.006027659303914e-07, 'threshold': 0.5641007712030841}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 155 for F0.5 optimization\n",
      "INFO:root:Trial 155 completed with average F0.5 Score: 0.6870280650375505\n",
      "[I 2024-10-02 15:04:24,461] Trial 155 finished with value: 0.6870280650375505 and parameters: {'xgb_learning_rate': 0.006826859696150867, 'xgb_n_estimators': 357, 'xgb_max_depth': 11, 'xgb_subsample': 0.8524468791027247, 'xgb_colsample_bytree': 0.6149241922978599, 'xgb_reg_alpha': 0.885686059821654, 'xgb_reg_lambda': 3.8005984486861624e-07, 'threshold': 0.5670502738099271}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 156 for F0.5 optimization\n",
      "INFO:root:Trial 156 completed with average F0.5 Score: 0.6871821314781781\n",
      "[I 2024-10-02 15:04:58,721] Trial 156 finished with value: 0.6871821314781781 and parameters: {'xgb_learning_rate': 0.004947850345242512, 'xgb_n_estimators': 366, 'xgb_max_depth': 11, 'xgb_subsample': 0.8650353911152701, 'xgb_colsample_bytree': 0.6371142767010538, 'xgb_reg_alpha': 0.3764932289035091, 'xgb_reg_lambda': 2.799479914139972e-07, 'threshold': 0.5758207213666483}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 157 for F0.5 optimization\n",
      "INFO:root:Trial 157 completed with average F0.5 Score: 0.6856644240656314\n",
      "[I 2024-10-02 15:05:25,884] Trial 157 finished with value: 0.6856644240656314 and parameters: {'xgb_learning_rate': 0.006171363771269679, 'xgb_n_estimators': 345, 'xgb_max_depth': 10, 'xgb_subsample': 0.847798945368062, 'xgb_colsample_bytree': 0.6056911754972428, 'xgb_reg_alpha': 0.6530092233157679, 'xgb_reg_lambda': 8.297103444078519e-07, 'threshold': 0.5411671047216876}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 158 for F0.5 optimization\n",
      "INFO:root:Trial 158 completed with average F0.5 Score: 0.6851121876336107\n",
      "[I 2024-10-02 15:06:02,188] Trial 158 finished with value: 0.6851121876336107 and parameters: {'xgb_learning_rate': 0.0034560794751519407, 'xgb_n_estimators': 382, 'xgb_max_depth': 11, 'xgb_subsample': 0.8309775586272802, 'xgb_colsample_bytree': 0.6242754541903922, 'xgb_reg_alpha': 0.2862454468291062, 'xgb_reg_lambda': 1.839773179870258e-07, 'threshold': 0.5065834444665146}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 159 for F0.5 optimization\n",
      "INFO:root:Trial 159 completed with average F0.5 Score: 0.6862601768147822\n",
      "[I 2024-10-02 15:06:34,739] Trial 159 finished with value: 0.6862601768147822 and parameters: {'xgb_learning_rate': 0.007420232660882745, 'xgb_n_estimators': 360, 'xgb_max_depth': 11, 'xgb_subsample': 0.8711486231185464, 'xgb_colsample_bytree': 0.6373969309607683, 'xgb_reg_alpha': 0.46609546778409394, 'xgb_reg_lambda': 3.209459897129957e-07, 'threshold': 0.607467584241166}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 160 for F0.5 optimization\n",
      "INFO:root:Trial 160 completed with average F0.5 Score: 0.6859172972433878\n",
      "[I 2024-10-02 15:07:11,095] Trial 160 finished with value: 0.6859172972433878 and parameters: {'xgb_learning_rate': 0.005446724653045845, 'xgb_n_estimators': 397, 'xgb_max_depth': 11, 'xgb_subsample': 0.858117053970742, 'xgb_colsample_bytree': 0.6439964411340523, 'xgb_reg_alpha': 0.6276711042440106, 'xgb_reg_lambda': 1.4493718219097506e-07, 'threshold': 0.5531878106981845}. Best is trial 148 with value: 0.688637380527025.\n",
      "INFO:root:Starting trial 161 for F0.5 optimization\n",
      "INFO:root:Trial 161 completed with average F0.5 Score: 0.6889231097730735\n",
      "[I 2024-10-02 15:07:45,908] Trial 161 finished with value: 0.6889231097730735 and parameters: {'xgb_learning_rate': 0.007937612759955569, 'xgb_n_estimators': 389, 'xgb_max_depth': 11, 'xgb_subsample': 0.8781101756890797, 'xgb_colsample_bytree': 0.6570721707486152, 'xgb_reg_alpha': 0.9279430516272091, 'xgb_reg_lambda': 2.0261290711123077e-07, 'threshold': 0.5672599248406032}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 162 for F0.5 optimization\n",
      "INFO:root:Trial 162 completed with average F0.5 Score: 0.6879427312986615\n",
      "[I 2024-10-02 15:08:19,098] Trial 162 finished with value: 0.6879427312986615 and parameters: {'xgb_learning_rate': 0.00797677502393835, 'xgb_n_estimators': 368, 'xgb_max_depth': 11, 'xgb_subsample': 0.873924621867958, 'xgb_colsample_bytree': 0.6534767581414525, 'xgb_reg_alpha': 0.7586937950722106, 'xgb_reg_lambda': 2.01814057120267e-07, 'threshold': 0.58675676254921}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 163 for F0.5 optimization\n",
      "INFO:root:Trial 163 completed with average F0.5 Score: 0.6864364783061531\n",
      "[I 2024-10-02 15:08:50,823] Trial 163 finished with value: 0.6864364783061531 and parameters: {'xgb_learning_rate': 0.007544193651822782, 'xgb_n_estimators': 347, 'xgb_max_depth': 11, 'xgb_subsample': 0.8930463979088857, 'xgb_colsample_bytree': 0.6485257872330406, 'xgb_reg_alpha': 0.9589949497242541, 'xgb_reg_lambda': 2.389813157384309e-07, 'threshold': 0.593072546811899}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 164 for F0.5 optimization\n",
      "INFO:root:Trial 164 completed with average F0.5 Score: 0.6876514111160582\n",
      "[I 2024-10-02 15:09:26,078] Trial 164 finished with value: 0.6876514111160582 and parameters: {'xgb_learning_rate': 0.006322069415210519, 'xgb_n_estimators': 387, 'xgb_max_depth': 11, 'xgb_subsample': 0.861195443491807, 'xgb_colsample_bytree': 0.6592332976368686, 'xgb_reg_alpha': 0.6270927591333021, 'xgb_reg_lambda': 4.2895459860592496e-07, 'threshold': 0.5775394224939489}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 165 for F0.5 optimization\n",
      "INFO:root:Trial 165 completed with average F0.5 Score: 0.6858161919179995\n",
      "[I 2024-10-02 15:09:56,311] Trial 165 finished with value: 0.6858161919179995 and parameters: {'xgb_learning_rate': 0.006423239313586275, 'xgb_n_estimators': 388, 'xgb_max_depth': 10, 'xgb_subsample': 0.8653153476518541, 'xgb_colsample_bytree': 0.6585085169054352, 'xgb_reg_alpha': 0.6562521434881537, 'xgb_reg_lambda': 4.5186931227285126e-07, 'threshold': 0.5788015550498788}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 166 for F0.5 optimization\n",
      "INFO:root:Trial 166 completed with average F0.5 Score: 0.6782190038975149\n",
      "[I 2024-10-02 15:10:32,656] Trial 166 finished with value: 0.6782190038975149 and parameters: {'xgb_learning_rate': 0.006046032229412296, 'xgb_n_estimators': 396, 'xgb_max_depth': 11, 'xgb_subsample': 0.8798793864184611, 'xgb_colsample_bytree': 0.6542239539546328, 'xgb_reg_alpha': 0.3660682762075174, 'xgb_reg_lambda': 1.0352004372427311e-06, 'threshold': 0.6299773085134486}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 167 for F0.5 optimization\n",
      "INFO:root:Trial 167 completed with average F0.5 Score: 0.6864019165468414\n",
      "[I 2024-10-02 15:11:11,604] Trial 167 finished with value: 0.6864019165468414 and parameters: {'xgb_learning_rate': 0.008265842409921217, 'xgb_n_estimators': 416, 'xgb_max_depth': 12, 'xgb_subsample': 0.8475934533671137, 'xgb_colsample_bytree': 0.6758606712068781, 'xgb_reg_alpha': 0.4720022359031232, 'xgb_reg_lambda': 2.0275441034232992e-07, 'threshold': 0.5982662379870562}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 168 for F0.5 optimization\n",
      "INFO:root:Trial 168 completed with average F0.5 Score: 0.6866702116756832\n",
      "[I 2024-10-02 15:11:47,769] Trial 168 finished with value: 0.6866702116756832 and parameters: {'xgb_learning_rate': 0.003969593994959663, 'xgb_n_estimators': 381, 'xgb_max_depth': 11, 'xgb_subsample': 0.8952759448443626, 'xgb_colsample_bytree': 0.6372236391785269, 'xgb_reg_alpha': 0.8481483686181418, 'xgb_reg_lambda': 4.009748746529657e-07, 'threshold': 0.5303569478478556}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 169 for F0.5 optimization\n",
      "INFO:root:Trial 169 completed with average F0.5 Score: 0.6867966181864114\n",
      "[I 2024-10-02 15:12:20,600] Trial 169 finished with value: 0.6867966181864114 and parameters: {'xgb_learning_rate': 0.006662147406567734, 'xgb_n_estimators': 356, 'xgb_max_depth': 11, 'xgb_subsample': 0.8778640070595654, 'xgb_colsample_bytree': 0.6506122705776196, 'xgb_reg_alpha': 0.2980269759943026, 'xgb_reg_lambda': 6.439944784796221e-07, 'threshold': 0.5777455357979292}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 170 for F0.5 optimization\n",
      "INFO:root:Trial 170 completed with average F0.5 Score: 0.6855880475591962\n",
      "[I 2024-10-02 15:12:54,452] Trial 170 finished with value: 0.6855880475591962 and parameters: {'xgb_learning_rate': 0.008289490072635868, 'xgb_n_estimators': 338, 'xgb_max_depth': 12, 'xgb_subsample': 0.8156961907268606, 'xgb_colsample_bytree': 0.6646942328309553, 'xgb_reg_alpha': 0.6162158222734933, 'xgb_reg_lambda': 1.4882997387377163e-07, 'threshold': 0.5479781807552953}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 171 for F0.5 optimization\n",
      "INFO:root:Trial 171 completed with average F0.5 Score: 0.6883276004894177\n",
      "[I 2024-10-02 15:13:27,557] Trial 171 finished with value: 0.6883276004894177 and parameters: {'xgb_learning_rate': 0.00730659527384415, 'xgb_n_estimators': 367, 'xgb_max_depth': 11, 'xgb_subsample': 0.8583817908419183, 'xgb_colsample_bytree': 0.6330569453118413, 'xgb_reg_alpha': 0.4489687413438134, 'xgb_reg_lambda': 2.824367369356438e-07, 'threshold': 0.570012139737132}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 172 for F0.5 optimization\n",
      "INFO:root:Trial 172 completed with average F0.5 Score: 0.6845101396324546\n",
      "[I 2024-10-02 15:14:01,608] Trial 172 finished with value: 0.6845101396324546 and parameters: {'xgb_learning_rate': 0.005568879346000359, 'xgb_n_estimators': 374, 'xgb_max_depth': 11, 'xgb_subsample': 0.8347989461715781, 'xgb_colsample_bytree': 0.6324727037736482, 'xgb_reg_alpha': 0.9851063993964135, 'xgb_reg_lambda': 3.0921727731222337e-07, 'threshold': 0.5918750739419538}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 173 for F0.5 optimization\n",
      "INFO:root:Trial 173 completed with average F0.5 Score: 0.6834903781808709\n",
      "[I 2024-10-02 15:14:36,740] Trial 173 finished with value: 0.6834903781808709 and parameters: {'xgb_learning_rate': 0.00678242896853399, 'xgb_n_estimators': 388, 'xgb_max_depth': 11, 'xgb_subsample': 0.8675749502904307, 'xgb_colsample_bytree': 0.6540140670370107, 'xgb_reg_alpha': 0.4467837390928155, 'xgb_reg_lambda': 2.1587522090706966e-07, 'threshold': 0.6160013849231556}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 174 for F0.5 optimization\n",
      "INFO:root:Trial 174 completed with average F0.5 Score: 0.6883082457711389\n",
      "[I 2024-10-02 15:15:09,628] Trial 174 finished with value: 0.6883082457711389 and parameters: {'xgb_learning_rate': 0.008039450129085914, 'xgb_n_estimators': 366, 'xgb_max_depth': 11, 'xgb_subsample': 0.8459403486906772, 'xgb_colsample_bytree': 0.6678201417248089, 'xgb_reg_alpha': 0.28782219068771325, 'xgb_reg_lambda': 3.910805672116145e-07, 'threshold': 0.5767302052765622}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 175 for F0.5 optimization\n",
      "INFO:root:Trial 175 completed with average F0.5 Score: 0.6860325469116711\n",
      "[I 2024-10-02 15:15:41,201] Trial 175 finished with value: 0.6860325469116711 and parameters: {'xgb_learning_rate': 0.007514122422519923, 'xgb_n_estimators': 350, 'xgb_max_depth': 11, 'xgb_subsample': 0.8456402399039961, 'xgb_colsample_bytree': 0.6437470448613387, 'xgb_reg_alpha': 0.28327654611829806, 'xgb_reg_lambda': 1.6119380193965852e-06, 'threshold': 0.5410041394513235}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 176 for F0.5 optimization\n",
      "INFO:root:Trial 176 completed with average F0.5 Score: 0.685023314644534\n",
      "[I 2024-10-02 15:16:15,528] Trial 176 finished with value: 0.685023314644534 and parameters: {'xgb_learning_rate': 0.004440007907175092, 'xgb_n_estimators': 367, 'xgb_max_depth': 11, 'xgb_subsample': 0.8547796075399554, 'xgb_colsample_bytree': 0.6353501787780241, 'xgb_reg_alpha': 0.588595636876332, 'xgb_reg_lambda': 4.878494235193945e-07, 'threshold': 0.5809433324272195}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 177 for F0.5 optimization\n",
      "INFO:root:Trial 177 completed with average F0.5 Score: 0.6868576363483225\n",
      "[I 2024-10-02 15:16:50,058] Trial 177 finished with value: 0.6868576363483225 and parameters: {'xgb_learning_rate': 0.00863791875864441, 'xgb_n_estimators': 428, 'xgb_max_depth': 11, 'xgb_subsample': 0.8404714337680171, 'xgb_colsample_bytree': 0.6192284052657387, 'xgb_reg_alpha': 0.32520635609789544, 'xgb_reg_lambda': 1.0248060829836432e-06, 'threshold': 0.5198719352290271}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 178 for F0.5 optimization\n",
      "INFO:root:Trial 178 completed with average F0.5 Score: 0.6837112525941079\n",
      "[I 2024-10-02 15:17:26,731] Trial 178 finished with value: 0.6837112525941079 and parameters: {'xgb_learning_rate': 0.005941457499982549, 'xgb_n_estimators': 400, 'xgb_max_depth': 11, 'xgb_subsample': 0.8609302576676463, 'xgb_colsample_bytree': 0.6651206567928796, 'xgb_reg_alpha': 0.20081780849416422, 'xgb_reg_lambda': 3.147223789021841e-07, 'threshold': 0.6063822491884926}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 179 for F0.5 optimization\n",
      "INFO:root:Trial 179 completed with average F0.5 Score: 0.6863148496997867\n",
      "[I 2024-10-02 15:17:52,036] Trial 179 finished with value: 0.6863148496997867 and parameters: {'xgb_learning_rate': 0.007187098607654426, 'xgb_n_estimators': 382, 'xgb_max_depth': 9, 'xgb_subsample': 0.8333773912633022, 'xgb_colsample_bytree': 0.6804692005476196, 'xgb_reg_alpha': 0.46909364834057066, 'xgb_reg_lambda': 7.767558699819592e-07, 'threshold': 0.567546981311647}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 180 for F0.5 optimization\n",
      "INFO:root:Trial 180 completed with average F0.5 Score: 0.686392271016205\n",
      "[I 2024-10-02 15:18:19,938] Trial 180 finished with value: 0.686392271016205 and parameters: {'xgb_learning_rate': 0.008502004346435044, 'xgb_n_estimators': 362, 'xgb_max_depth': 10, 'xgb_subsample': 0.8705994631228932, 'xgb_colsample_bytree': 0.6278862855738232, 'xgb_reg_alpha': 0.74389281593263, 'xgb_reg_lambda': 1.5482273859882097e-07, 'threshold': 0.5374244828244648}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 181 for F0.5 optimization\n",
      "INFO:root:Trial 181 completed with average F0.5 Score: 0.6881519665628044\n",
      "[I 2024-10-02 15:18:54,860] Trial 181 finished with value: 0.6881519665628044 and parameters: {'xgb_learning_rate': 0.006626255992455047, 'xgb_n_estimators': 374, 'xgb_max_depth': 11, 'xgb_subsample': 0.8799273942901242, 'xgb_colsample_bytree': 0.6731946670492239, 'xgb_reg_alpha': 0.16195023040579776, 'xgb_reg_lambda': 2.4830310918526164e-07, 'threshold': 0.5682767242998144}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 182 for F0.5 optimization\n",
      "INFO:root:Trial 182 completed with average F0.5 Score: 0.6874215741408136\n",
      "[I 2024-10-02 15:19:30,768] Trial 182 finished with value: 0.6874215741408136 and parameters: {'xgb_learning_rate': 0.005405650325230085, 'xgb_n_estimators': 376, 'xgb_max_depth': 11, 'xgb_subsample': 0.8847191949919919, 'xgb_colsample_bytree': 0.653391410586178, 'xgb_reg_alpha': 0.1634764017008967, 'xgb_reg_lambda': 3.9724160993769995e-06, 'threshold': 0.587057716187102}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 183 for F0.5 optimization\n",
      "INFO:root:Trial 183 completed with average F0.5 Score: 0.6883167675055477\n",
      "[I 2024-10-02 15:20:07,436] Trial 183 finished with value: 0.6883167675055477 and parameters: {'xgb_learning_rate': 0.0066067427905122655, 'xgb_n_estimators': 392, 'xgb_max_depth': 11, 'xgb_subsample': 0.8749994816365398, 'xgb_colsample_bytree': 0.6679500028827631, 'xgb_reg_alpha': 0.2490121655614448, 'xgb_reg_lambda': 2.26444500832615e-07, 'threshold': 0.558090950250399}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 184 for F0.5 optimization\n",
      "INFO:root:Trial 184 completed with average F0.5 Score: 0.6872625083467425\n",
      "[I 2024-10-02 15:20:44,206] Trial 184 finished with value: 0.6872625083467425 and parameters: {'xgb_learning_rate': 0.006494415611532469, 'xgb_n_estimators': 394, 'xgb_max_depth': 11, 'xgb_subsample': 0.8722419159500826, 'xgb_colsample_bytree': 0.6787089631428662, 'xgb_reg_alpha': 0.38246613860003026, 'xgb_reg_lambda': 4.6447841175650455e-07, 'threshold': 0.556962071301016}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 185 for F0.5 optimization\n",
      "INFO:root:Trial 185 completed with average F0.5 Score: 0.6859913156190058\n",
      "[I 2024-10-02 15:21:19,853] Trial 185 finished with value: 0.6859913156190058 and parameters: {'xgb_learning_rate': 0.004817293186072089, 'xgb_n_estimators': 370, 'xgb_max_depth': 11, 'xgb_subsample': 0.8819647266237148, 'xgb_colsample_bytree': 0.6393736709645862, 'xgb_reg_alpha': 0.25581507726850555, 'xgb_reg_lambda': 3.0079681469140936e-07, 'threshold': 0.5817121079243052}. Best is trial 161 with value: 0.6889231097730735.\n",
      "INFO:root:Starting trial 186 for F0.5 optimization\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Ensure the model directory is clean\n",
    "        model_dir = 'models'\n",
    "        for file in os.listdir(model_dir):\n",
    "            if file.endswith('.joblib'):\n",
    "                os.remove(os.path.join(model_dir, file))\n",
    "\n",
    "        model_configs = {\n",
    "            'xgb': {'learning_rate': 0.01, 'n_estimators': 100, 'max_depth': 6}\n",
    "        }\n",
    "\n",
    "        slack_channel = '#hyperparametertuning'\n",
    "\n",
    "        # Initialize and run the predictor\n",
    "        predictor = XGBoostPredictor(datasets, model_configs, slack_channel=slack_channel)\n",
    "        train_metrics = predictor.train_and_evaluate()\n",
    "        holdout_metrics = predictor.evaluate_on_holdout(datasets['full_data']['test'])\n",
    "\n",
    "        # Save training metrics to a JSON file with a unique identifier\n",
    "        train_metrics_file = os.path.join(predictor.model_dir, f\"train_metrics_{datetime.now().strftime('%Y%m%d%H%M%S')}.json\")\n",
    "        train_metrics.to_json(train_metrics_file, orient='records', lines=True)\n",
    "        print(f\"Training metrics saved to {train_metrics_file}\")\n",
    "\n",
    "        # Save holdout metrics to a JSON file with a unique identifier\n",
    "        holdout_metrics_file = os.path.join(predictor.model_dir, f\"holdout_metrics_{datetime.now().strftime('%Y%m%d%H%M%S')}.json\")\n",
    "        holdout_metrics.to_json(holdout_metrics_file, orient='records', lines=True)\n",
    "        print(f\"Holdout metrics saved to {holdout_metrics_file}\")\n",
    "\n",
    "        # Load SHAP values from the saved JSON file\n",
    "        with open(os.path.join(predictor.model_dir, 'shap_values.json'), 'r') as f:\n",
    "            shap_values_dict = json.load(f)\n",
    "\n",
    "        average_shap_values_dict = average_shap_values(shap_values_dict)\n",
    "        feature_names = datasets[\"full_data\"][\"train\"].drop(columns=['merged_category'], errors='ignore').columns.tolist()\n",
    "        combined_df = combine_and_average_shap_values(average_shap_values_dict, feature_names)\n",
    "        combined_df.to_csv(os.path.join(predictor.model_dir, 'combined_shap_values.csv'), index=False)\n",
    "\n",
    "        plot_combined_shap_values(combined_df)\n",
    "\n",
    "        # Perform ensemble evaluation\n",
    "        #ensemble_predictor = EnsemblePredictor(model_dir=predictor.model_dir, slack_channel=slack_channel)\n",
    "        #ensemble_metrics = ensemble_predictor.evaluate_on_holdout(datasets['full_data']['test'])\n",
    "        #print(ensemble_metrics)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Send a Slack message if an error occurs\n",
    "        send_slack_message(slack_channel, f\"Script encountered an error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
